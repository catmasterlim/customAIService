{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/stlim/Works/knd/customAIService/.venv/lib/python3.10/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-24.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q langchain_community\n",
    "!pip install -q langchain-ollama\n",
    "!pip install -q langgraph langsmith \n",
    "!pip install -q tavily-python\n",
    "\n",
    "!pip install -q streamlit-chat\n",
    "!pip install -q faiss-cpu\n",
    "!pip install -q langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "import os\n",
    "import random\n",
    "def get_tavily_api_key() -> str:\n",
    "    random_number = random.randint(1, 7)\n",
    "    # random_number = 7\n",
    "    print(f\"--> TAVILY_API_KEY_{random_number}\")\n",
    "    return os.getenv(f\"TAVILY_API_KEY_{random_number}\")\n",
    "\n",
    "def get_tavily_retriever() -> TavilySearchAPIRetriever:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = get_tavily_api_key()    \n",
    "    return TavilySearchAPIRetriever(k=2, api_key=get_tavily_api_key())\n",
    "\n",
    "def get_tavily_search_results() -> TavilySearchResults:    \n",
    "    os.environ[\"TAVILY_API_KEY\"] = get_tavily_api_key()\n",
    "    return TavilySearchResults(max_results=2)\n",
    "\n",
    "\n",
    "\n",
    "# result = get_tavily_search_results().invoke({'query':\"What is LangChain?\"})\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama3.2-vision:latest\n",
      "Name: EEVE-Korean-Q5_K_M:latest\n",
      "Name: llama3.2:latest\n"
     ]
    }
   ],
   "source": [
    "from ollama import list\n",
    "from ollama import ListResponse\n",
    "\n",
    "response: ListResponse = list()\n",
    "\n",
    "for model in response.models:\n",
    "  print('Name:', model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:52:30\n",
      "[HumanMessage(content='안녕하222세요?', additional_kwargs={}, response_metadata={}, id='1'), AIMessage(content='반갑습니다~', additional_kwargs={}, response_metadata={}, id='2')]\n",
      "⏳ 실행 시간: 0.03초\n"
     ]
    }
   ],
   "source": [
    "## test add_messages\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "# 기본 사용 예시\n",
    "msgs1 = [HumanMessage(content=\"안녕하세요?\", id=\"1\")]\n",
    "msgs2 = [AIMessage(content=\"반갑습니다~\", id=\"2\")]\n",
    "msgs3 = [HumanMessage(content=\"안녕하222세요?\", id=\"1\")]\n",
    "result1 = add_messages(msgs1, msgs2)\n",
    "result2 = add_messages(result1, msgs3)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2\"\n",
    "# llm = OllamaLLM(model=model_name)\n",
    "llm = ChatOllama(model=model_name, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:16\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is an open-source project that aims to simplify interoperability between blockchain networks and traditional software applications. Here's a breakdown of what it does:\\n\\n1. **Layering**: LangChain introduces the concept of layering, where blockchain-specific functionality is integrated into existing software layers, making it easier for developers to incorporate blockchain capabilities into their projects.\\n\\n2. **Web3 Integration**: It provides an interface for interacting with Web3 applications (e.g., Ethers.js), allowing developers to access and manipulate blockchain data, perform transactions, and more within the context of their existing applications.\\n\\n3. **Decentralized Data Storage**: LangChain enables decentralized storage solutions like IPFS (InterPlanetary File System) or Swarm, which can be used for storing and retrieving data in a secure and decentralized manner.\\n\\n4. **Blockchain Network Agnostic**: It allows developers to easily switch between different blockchain networks without having to rewrite their code, making it easier to experiment with different networks and find the best fit for their project's needs.\\n\\n5. **High-Level Abstractions**: LangChain provides high-level abstractions for common blockchain-related tasks, such as token management, smart contract interactions, and more, making it easier for developers to build blockchain-enabled applications without having to delve into low-level details of blockchain protocols.\\n\\nBy simplifying the integration of blockchain capabilities into traditional software applications, LangChain aims to make blockchain development more accessible and user-friendly.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T02:53:28.106953433Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9018536368, 'load_duration': 4763800118, 'prompt_eval_count': 41, 'prompt_eval_duration': 383000000, 'eval_count': 286, 'eval_duration': 3869000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-2ae80a31-1e5b-4706-92be-b58c1b3366c1-0', usage_metadata={'input_tokens': 41, 'output_tokens': 286, 'total_tokens': 327})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 실행 시간: 9.26초\n"
     ]
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 10:58:44\n",
      "--> messages : [SystemMessage(content='answer is korean', additional_kwargs={}, response_metadata={}, id='1'), HumanMessage(content='현재 시간은!', additional_kwargs={}, response_metadata={}, id='2')]\n",
      "--> messages type : <class 'list'>\n",
      "⏳ 실행 시간: 2.41초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"answer is korean\", id=\"1\"),\n",
    "    HumanMessage(\"현재 시간은!\", id=\"2\"),\n",
    "]\n",
    "print(f\"--> messages : {messages}\")\n",
    "print(f\"--> messages type : {type(messages)}\")\n",
    "response = chain.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-11-28 15:09:35\n",
      "Step 1: Understand the context of the question.\n",
      "The given text appears to be a list of message objects, which consists of two messages - one labeled \"SystemMessage\" and another labeled \"HumanMessage.\" These messages are meant for processing by an AI assistant like myself.\n",
      "\n",
      "Step 2: Analyze the content of each message.\n",
      "- SystemMessage(content='answer is korrea', additional_kwargs={}, response_metadata={}, id='1'): This message has the content \"answer is korrea\" and no additional keywords or response metadata. We can assume that it's a question, but it may have some spelling mistakes.\n",
      "- HumanMessage(content='현재 시간은!' additional_kwargs={}, response_metadata={}, id='2'): This message simply states, \"현재 시간은!\" which translates to \"What time is it now?\" in English. It seems like a request for the current time.\n",
      "\n",
      "Step 3: Combine both messages for clarity and provide an answer.\n",
      "Since the first message appears to be a question but has spelling mistakes, we can assume that it's asking about the current time as well. The correct phrase should be \"What is the answer in Korea?\" or simply \"What's the time in Korea?\" Combining both messages, we can provide an answer:\n",
      "\n",
      "Answer: Based on your two messages, I understand you are interested in knowing the current time in Korea. As of now, it is [insert the current time in Korean Standard Time (KST) here].\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:39\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Any, List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class TestState(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "        #  messages: list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:24:57\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n",
    "def chatbot(state: TestState) -> TestState:\n",
    "    # print(f\"--> chatbot : start state: {state}\")\n",
    "    print(f\"--> chatbot messages : {type(state['messages'])}\")\n",
    "    print(f\"--> chatbotmessages : {state['messages']}\")\n",
    "    tools = [get_tavily_search_results()]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    # response = llm_with_tools.invoke(state['messages'])\n",
    "\n",
    "    # print(f\"--> chatbot : after chain.invoke : {response}\")\n",
    "    # # Create an AIMessage instead of returning raw response\n",
    "    # from langchain_core.messages import AIMessage\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 12:00:07\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A Node that runs requested in the last AI message\"\"\"\n",
    "\n",
    "    def __init__(self, tools: List[BaseTool]):\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs:dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            messages = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No messages found in inputs\")\n",
    "        \n",
    "        output = []\n",
    "        for tool_call in messages.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "                )\n",
    "            output.append(ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": output}\n",
    "    \n",
    "tool_node = BasicToolNode([get_tavily_search_results()])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def search_wikipedia(state: TestState) -> TestState:\n",
    "    # print(f\"--> chatbot : start state: {state}\")\n",
    "    print(f\"--> messages : {type(state['messages'])}\")\n",
    "    print(f\"--> messages : {state['messages']}\")\n",
    "\n",
    "    response = chain.invoke(state['messages'])\n",
    "\n",
    "    print(f\"--> chatbot : after chain.invoke : {response}\")\n",
    "    # Create an AIMessage instead of returning raw response\n",
    "    from langchain_core.messages import AIMessage\n",
    "    return {\"messages\": [AIMessage(content=str(response))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:46:59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAEjCAIAAAA628qRAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BPdkIICRA2sl0VFRTce+FELA6qotZRZ/3VatW2Vq27ra1WrfZbd4t7VOuo2GoddYAbEUFZMgIIAbIgO78/rl++VoMCJnwul/fz4R945I5XCK/c5cbnaCaTCQEAyIGOOwAA4H+gkACQCBQSABKBQgJAIlBIAEgECgkAiTBxB7BrBr3peZ5apTBUKfRGPdJqjLgT1QmbS+fy6Q4CpkDEdPZg445DKTQ4Dtn4tBpjxm1F9kNlYWa1VyCP60B3EDCFbixttW0U0mg0Kcr1VQo9h8coLdQEhvKDWvO9g3i4c1EBFLKxJf0uzX6o9ArkBbV29GvhgDvO26os1eakqqTFWmWFvsswV/cmXNyJbBsUsvFkPlD8kfC8fT/nDlEuuLNYXv6TquunpF5B3B4j3HBnsWFQyEZy86xUJdf3jHVjsqi8Iy3nkerK8dL3FvqxOVR+mtYDhWwMSb9L6Qxa5AAKrhhfJZfqDnydN3llIIsNnaw3KKTVnf+lWOjG6jjQFXeQRrX9s+zxn/nzHBm4g9gYeA+zrrsXK/hCpr21ESE0drHfga/zcKewPVBIK8rLUCnK9V2jxbiDYMB3Yg6I9/jrcAnuIDYGCmlFV46XtekuxJ0CG9+mDvJyfV56Fe4gtgQKaS2Pk+We/lw7P5Gl6zDxtVNluFPYEiiktWTeV3aNtruPji8R+3D8mztkpShxB7EZUEirKMqt1lQZeY6NdKpwUVGRRCLBNfvruTXhPL0HhawrKKRV5KSqAkP5jfOzCgoKoqOj09LSsMz+RoGh/JxUlZUWTj1QSKuQSrRBbRqpkHq9vmEHk4m5Gjx7HTFZ9JBwx/wn0Mk6gRMDrGLr/MzpXwczGDTLLlatVq9bt+7KlSsIofDw8AULFphMpujo6JoHDB06dPny5Vqtdvv27YmJiSUlJWKxeMiQIdOnT2cwGAih0aNHBwcHBwcHHzx4UK1W7969+7333ntpdstmRghdOvrc1ZPTupv97nCuO7ge0vKqVQY2l27xNiKEdu/effr06RkzZojF4tOnT/N4PAcHh1WrVi1ZsmTGjBkREREuLi4IIQaDkZSU1KNHD19f34yMjF27djk5OY0fP55YyI0bN9Rq9YYNG6qqqvz9/V+d3eL4TkyVXG+NJVMPFNLyqmR6B6FVfrESiYTH402aNInJZMbExBATW7RogRAKCAgICwsjpjAYjL1799Jo/7wjFBQUXLx4saaQTCZzzZo1PB6vttktji9kFmVXW2nhFAOfIS3PYDTxHKzyix00aJBarf7www8zMzNf/8jy8vJ169bFxMT06dMnKytLKpXWfCs0NLSmjY2DyaTRrLC9QElQSMvjOzErnuusseQuXbp8//33Uqk0Li5u1apVer357UCpVDpu3Ljk5OSZM2du3ry5ZcuWBoOh5ruN3EaEkKJSz+XBX1qdwCar5fGdmFUKQx0e2BBdunTp1KnTgQMHNmzY4OXlNWXKlFcfc+zYsfLy8j179nh6eiKEPD09nz17ZqU8daGS64UuLIwBbAi8b1lFwDsOykrLryS1Wi1CiE6njxs3zs3NLT09HSHE5XIRQqWlpTUPq6ysdHZ2JtpI/Pc1+9Jfnd3iaAg5ieGtv07g12QVAmdWdqqqTTeRZRd78ODBy5cvDx48uLS0tLS09J133kEIeXh4+Pj4JCQk8Hg8mUwWFxcXERFx+PDhbdu2tW3b9uLFi9euXTMajZWVlSKRmTyvzs7hcCwbO+VvmX1e8tIAsIa0CiudnuLr66vVajds2HDixIm4uLj4+HiEEI1GW7NmDZ/PX79+/alTp8rLy/v06TN16tQjR458/vnnOp1uz549AQEBhw4dMrvMV2e3bOZnj1VNmjnQYadO3cCJAdZyfHNBzGwfOt3e/xCTEqUCEfOdjnBWQJ3AJqu1+Lfk3zwr7TK01k21gQMHqtXqV6e3adMmJSXl1elCofDkyZOWjvmyLVu2HD169NXpAoFAoVCYneXPP/9kMs3/IVUp9Kl/y6esDLR0TMqCNaQV/fRp9sSl/hye+XFliouLjcZ6jIxMp9Nr9tNYj0wmU6nqt7Ht5eVVcxLCS/7cX+ITwmvZwclC6agPCmlF6bfksjJdx0F2elVkZan2xhnpoEleuIPYEtipY0UtIp1UcsOjGzLcQfA4+E1+v7EeuFPYGCikdfUZ4552U56bZncXHx1cnxczyweGZq0v2GRtDKe3S1p0EIS0FeAO0kgOfZs/cJKH0NWuxxNqGHgDawxDp3k/uaO8e7ECdxCrqyzV/rgwq2esG7SxYWAN2Xhu/1GeliTvMkwc0tYRdxbLq1Lor5+S6rTGfmM9YEu1waCQjUpWprt+qsxoRH7NHQJD+Y4iKhwHzkuvKs6tfnhN3mWYKxzheEtQSAyKn6nTb8lzUlUOjkyPAI6DgMl3YjiKmAZrXSJiYUa9UVGhV8kMJmR6+LfMJ4TXLFzQsiNU0QKgkDg9L1A/z9OoZHqV3MBg0pSVFh7nIj09vUmTJny+hYfb4jrQOQ4MvpAhdGX5t+QzmPZ+eqAFQSGpbNKkSfPnz2/dujXuIKCu4MM3ACQChQSARKCQVNakSRM6HV5iWwKvFpXl5+fX64ISgB0UksocHR1ruzAKkBMUksqUSiXsRbctUEgqc3FxgTWkbYFCUll5eTmsIW0LFJLK/P39YS+rbYFXi8qePXsGe1ltCxQSABKBQlKZkxNcgWFjoJBUJpfLcUcA9QOFpDKhUAiHPWwLFJLKZDIZHPawLVBIAEgECkllXl5ecBzStsCrRWVFRUVwHNK2QCEBIBEoJJX5+fnBJqttgVeLyvLy8mCT1bZAIQEgESgklQUEBMAmq22BV4vKcnNzYZPVtkAhASARKCSVwTCQNgdeLSqDYSBtDhQSABKBQlIZjMtqc6CQVAbjstocKCSVeXt7w04d2wKvFpVJJBLYqWNboJAAkAgUksqcnZ1hp45tgUJSWUVFBezUsS1QSCqDWwnYHHi1qAxuJWBzoJBUBmtImwOvFpXBGtLmQCGpzM3NDfay2hYa7IWjnqioKDabTaPRysvL+Xw+8TWbzT569CjuaOANmLgDAMvj8/l5eXnE12q1mvhi1qxZWEOBOoFNVgoaMGDAS1P8/Pzee+89THFAPUAhKWjUqFF+fn41/2UwGMOHD+fxeFhDgTqBQlKQq6trv379av7r7+8/cuRIrIlAXUEhqWn06NH+/v7E6nHIkCF8Ph93IlAnUEhqEovFffr0odFofn5+sHq0IbCXtZHotcbyEq1KZmi0o0xdw9+9dTmve/fuJTkIIVXj/FAmi+bqxeY7wd9VA8FxyMaQ9Lv0yT0lk0UXill6LZV/4Q5OjGdpKg9/bq+Rbo4iqGW9QSGt7vKxUkSjt+vrijtI46l4rrlypHjEbB++EDpZP/AZ0rqu/VZGZ9hXGxFCzu6codP99q7MxR3E9kAhrUhRqSt5pg7rbV9tJDCYtA6D3JITpbiD2BgopBVVFOtodPs9t1vgzJJkq3GnsDFQSCtSVOicPbi4U2AjcGEZ9LhD2BoopBWZTEirNuBOgY3JhFQyaGT9QCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIlBIAEgECgkAiUAhASARKCQAJAKFBIBEoJC2YdjwXtt+3FjfuYqLi4qKJTX/PXpsf+++EVVVVfVdTtrjVI1GU9+5QANAISmrUFIwdnx0RkbaWy7nXOKp2XMmqdXVFsoFXgcKSVkGvd4i47PAurExwZAnpHP295PHfz2Yl5fr6Cjo0rnHlMmznJ1dEEJKpWL12i+uXbskdBLFxU0cHj0SIaTVan/+ZfvFi4nPS0tcXcUD+g+ZNHE6g8EoKpZMfH8kQujLFYu/RCgqaujihcuJ5e/YueXK1YvV1VUR7TvNmvmxh4cnMT3tceqP/9mYkZHG5fK6dO4xc+Y8J4HTucRTG79fhxCKebcfQmjRwmUDo4Zh/fVQHBSSXPbs/c/en7f36tlvVOy4isryW7duMFks4lu/n/stasDQeR99dvGvxI3frwsMCG7TJpzBYNy5k9S5Sw9vL9/MzIyEfbsEAqfRo8a7uog//2zV6jVL3p80Izwsgqg0obT0+bQpc7JzMn89cSjjSdr2nw4IHAW5udnzF8wICAhe+MkyWWXF7j0/Pn9e/O36bR07dB09avzhIwlrV2/k8x19ff1qzw4sAApJIlJpWcK+Xf37D/5s8QpiStyYCTXfHdB/yKKFyxBC3bv1Hj1m0KXLfxCF3PrD3pqbQEqKCq5cvTh61Hg2m92saQuEkJ9fQOvWYS/+lE8Xr3BwcEAIhbVt/9mSecePH5w4YVrCvp10Ov3rr7YIHAUIIYHAac26pQ8e3G3btp23ty9CqGXLUKFQ1Li/D3sEhSSRByl3DQbD8GHmBxqv6QOXy/X29n1eWkL8t6Ki/Odftt+6fVOhkCOEiEbVRefO3T09vO7fvz1xwrT7D+6Eh0fWzBsZ2RkhlPEkrW3bdpZ4ZqCuoJAkUllZgRByc/N44yPpDIbBYEAIlZdLP5gxjsdzmPz+TG9v3127tuYXPKv7TxS7uatUSoSQSqUUCZ1rpgsETgihsrLShj4V0EBQSBJx5DsihMorpO7ub+4k4bdTxyoqyn/YvIfYN+Pu7lmvQlZUlPt4+yKExGJ3uVz24nSEkOMLK1sYULtxwGEPEmkV2hYhdPbsiZopev0bBomSyytFIueaPaUyeWVNczgcLkJIWvta7mlmRmFhfrt2HRBCrVq1uf/gTs3tlq9cuYAQIj588rg8WFs2GlhDkoiPt+/QISNOnT4ul8siIzvLZJWnTh377rv/eHl61zZLWFjErycO79q9rVWrtlevXkxKumY0GmWySqFQ5O7u4e3lc/hoApfHk8tl746II2ZZvXZJj259ioolv5445O3lM3TIuwih8WMnX7yYuOjTD4cNjX3+vHjvzz+Fh0WEtW1PvE0wGIwtW9cPiorWaDXRw2Ib8VdidxjLly/HnYGynudrFBWGJs3rcW/GTh27sdnsGzeuXPzrfGFBXmRk5/CwCD6ff+DgnqZNW0RGdCIedubsCS6X26/vQH//QJPJeOLkkatXLnj7NFkw/4uHD+9VV1eFhUXQaLR33mmTfOv6xb8Si4ol3br2zsvPdeQ7stmcEycPp6WlRER0WvL5amdnZ4SQk5OwdWj4rds3Tp0+lvHkce9eAz5ZsJTD4SCEnARObm4ely79cePGVYVCHhU1tI7PRVNtzHmoaNsD9s3WA9xsx4pSr8sk2ZrOw9xxB8FDXq67sE8yYYk/7iC2BD5DAkAiUEgASAQKCQCJQCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIlBIAEgECgkAiUAhASARKCQAJAKFtCI2l851YOBOgY3JaHLxYuNOYWOgkFbk7M4uyFThToFNmUTDZtNwp7AxUEgrcvPlcLh0TbUBdxA8yiVqBzcl7hQ2BgppXd1ixH/uk9ThgVRz7y+pyWjKKLw8ffp0rVaLO47NgBEDrE5apDmysaDDQLGTK9tRxESIyltxRqOptEAtlaiR0dQnzh0hdPv27YCAACaTKZVKg4ODcQckOyikFV24cGH//v07d+7Uaoy3E8slOWqt2qhVGxstgFqtZrFYDEbj7VgS+3CZLBTcht80/F/jNWs0mvj4+BEjRrz33nuNFsYmmYAVyGQyk8n01VdfVVVV4cpw69atqKioxYsX4wrwqnv37plMpsTExIqKCtxZSAo+Q1remjVr7t27hxBauHAhj8fDFeOXX34pLS1NTU19+PAhrgwvCQsLQwh5eXnFxsZKpVLYOnsVFNLCzp0717x58549e+KNkZycnJ6eTqPRioqK9u/fjzfMS1q3bn3hwgUGg5GUlLRjxw7cccgFCmkZubm5CxcuRAgNHDgwNhb/UMIJCQllZWXE1w8fPkxNTcWd6GUikahTp046ne7YsWO4s5AIFPJtVVdXI4SuXr06d+5c3Fn+kZycnJGRUXOPuqKiooSEBNyhzJs5c+bw4cMRQosXL7506RLuOPhBId/Knj17lixZghCKj4/39fXFHecfu3fvlkqlNf+l0WipqakpKSlYQ9WKyWQihBYsWHDq1Kni4uI33s6E2qCQDaTX6+VyuUKh+Pbbb3FneVl6evpL++6Kior27NmDO9friMXib7/9ViQSKZXKlStXGo2Nd3CIVOA4ZL0ZjcYvvvhiyZIlHA6HTif1O9rEiRM/+eST0NBQ3EHq58SJEzk5OfPmzcMdBAO4+1W9ff/99927d8d4PKPuvL292Wzbu94iJiaG+GLFihVjxoxp3rw57kSNh9Rv8KRSWlq6bt06hNC8efMGDhyIO06dZGdnk3wd/nqTJ09evXo17hSNyoZfrUY2e/bskSNH4k5RPywWi8+vx83wyMbX1/fnn38mToi9f/8+7jiNAQr5BgUFBUlJSQihw4cPh4SE4I5TPzk5OcTtH21d27ZtN2/efOfOHdxBrA4K+To5OTmzZ89u1aoV7iANoVAovLy8uFwu7iAWwGKxdu7cSaztCwoKcMexIiikeWq1mrhG4eTJk46OjrjjNER+fr5N7HmquxYtWhCnEBDbLJQEhTQjLS0tKiqq5i/ARpWUlLRv3x53CstLSEiQSCh7zTcU0ox79+5dvnwZd4q3dfv2bU9PT9wprGLEiBEIoSVLlsjlctxZLAwK+T8Gg4HYyT5u3DjcWSxAIpHY3CkB9fLxxx9/9NFHuFNYGBTyfz744IP4+HjcKSxDqVTevXuX2oV0cXHZtWsXQohKe1+hkAghRFydtHPnTj8/P9xZLOPvv//u1q0b7hSNhITXfDYYFBLt3bs3NzcXdwoLS09P79+/P+4UjWTo0KE2fULSiyjyNN6GWq0eOnQo7hSWpFKpjh8/3qtXL9xBGk9cXFxZWVl2djbuIG/LrgtZUlIik8mmT5+OO4iFnThxoub8bPshFotTUlJWrlyJO8hbsd/Lr7755psmTZrExcXhDmJ506dPX7Zsmbe3N+4gGFRWVmo0Gg8PD9xBGshOCymVShkMhkgkwh3E8k6ePPngwYOlS5fiDoJNdnY2jUYLDAzEHaQh7HGTtaKiQqlUUrKNCKGtW7fOmjULdwqcgoKCfvrpp/Pnz+MO0hB2t4aUyWQjRoy4ePEi7iBWsXfvXqVSOXv2bNxB8MvNzfXy8uJwOLiD1I/dFfLcuXMRERFisRh3EMsrLS2Nj48/d+4c7iCkYDQaU1NT27RpgztI/djdJuvAgQMp2UaE0OrVq219H6MF0en04uLiTz/9FHeQ+rGvQo4ZM0ahUOBOYRUHDx708fGJjIzEHYREBgwYMGbMmMLCQtxB6sGOBrlKTEzs16+fQCCow2NtTGZm5q+//nro0CHcQUiHuJuIDbG7z5CUNGHChA0bNri6uuIOQkanTp0qLCycMWMG7iB1Yi+brGq1Oi8vD3cKq5g7d+706dOhjbUZNmzYnTt3iouLcQepE3tZQ+7du1cmk5Hn9huWsmnTJqFQOHHiRNxBgGXYyxpSp9MNGDAAdwoLu3DhgsFggDbWxc2bN1UqFe4Ub2Yva0jquXfv3g8//AD3V6yjY8eOZWRkfPbZZ7iDvIFdrCENBsONGzdwp7CkwsLCZcuWQRvrLjY21sPDw2Aw4A7yBnaxhiwrKxs3blxiYiLuIJah0+nmzp27bds23EGA5dnFGhIh1Lt3b9wRLKZbt26bN2/GncL2FBcXf/fdd7hTvIFdFFIsFi9evBh3Csvo3bv3H3/8QdzkFNSLp6fnzZs3s7KycAd5HbvYZNXpdA8ePIiIiMAd5G0NGjQoISEBDjk2GHE0kszD1dpFIRFCXbp0+euvv2zuYpwXRUVF7du3j6pnxgOCXWyyIoS4XO67774bFRXVqVOnMWPG4I5Tb5MnTz558iS08e3NmTOnsrISd4paUfyjCHFzCxqNhhAihp03mUzEfTtsSM+ePc+cOUON+1hh5+Licu3atSFDhuAOYh7F15DdunUj2ljDzc2tS5cu+BLVj06nmzFjxpkzZ2z0DlwktHDhwo4dO+JOUSuKf4asrKwcP358zYnFJpMpNDR07969uHPViUwmi4qKunr1KovFwp0FNBKKryFFItGcOXMcHBxqptjK8MFFRUXz58+/efMmtNHiYmNjlUol7hTmUbyQxJgdXbt2JTYEbGV7NTMzc9q0aXBmnJV4eHg8evQIdwrzKL7JStDpdKNGjSooKGjZsuUvv/yCO84bpKSkrF69Gi7/tx69Xk+j0RgMBu4gZtRpL6teZ6xWGq0fxnpoc2ct+vrrr/v0GKKo0OMO8zq5ubk/bNm148d9b5mTRkOOIorvQm8wOp1uNJL07/kNa8jHyfKUq7LyYi3PkYxvJ9Sj1WrZbPbbL0fszZHkVDcLF/SMFdPotDrMYUdSUlI2bNiwe/du3EHMeN2baPL58jKJrvu7ngIX2K9gezTVBqlE/cP8rA/WBbE51N9ZUHc+Pj6kHYqu1jVk0rlyuVTfaah7o0cClqTTGg+vz5nxVTDuIOSiVCrJeWjX/BtnxXNtWaEG2kgBLDa9yzC3G6fLcAchF3K2sdZClhVqTCb44EERTq7sZ+nVuFOQy6JFi1JSUnCnMMN8IZUyg1sTOHOSIpw9uSw2fIb8F+JGA7hTmGF+p45OY9SpGz0LsA6T0VSSBy/nvyxdupROJ+ObFByqAvaIx+PhjmAeGd8kALC2vXv3btq0CXcKM6CQwB45ODhUVVXhTmEGbLICezRy5EhynsUNhQT2iEajvXTlOknAJiuwR7dv34bPkACQhUqlys3NxZ3CDNhkBfaoffv2QUFBuFOYAYUE9sjR0ZGcp7PCJiuwR7du3VqzZg3uFGZAIYE9otFo5Lx/KwULmfY4VaPRvM0SLl3+s3ffiLw8Mn7oBxYRERGxevVq3CnMoFohzyWemj1nkloNVxuB19HpdMRI9mRDtUK+5boR2Inbt2+T8/bmlNrLei7x1Mbv1yGEYt7thxBatHDZwKhhCKHz58/sO7BbIilwdRUPGTxi3Nj3iUtvpNKybT9uSEq+ptfrW4eGzZj+UVBQyKuL3X9gz4mThxUKeUhI80kTp7dv1wHHkwMWMHz48Pz8fOLVN5lM7du3p9FoJpPpzp07uKP9g1JryI4duo4eNR4htHb1xk0bd3Ts0BUhlJh4eu1Xy5o2bfHFkjW9evbftXvbvv27EUJqtfrjBTPu3E3+YNrcjz/6rExa+vGCGQql4qVl3rmbvH3HljZt2n380WeeHl7VpDwjGdTRlClTai68Is6eM5lM4eHhuHP9D6XWkM7OLt7evgihli1DhUIR8S64Y9cPrVuHLflsFUKoR/c+CoX84KG9se++d+Hiuby83G/Xb2sXHokQat06fOz46OPHD06cMO3FZRYXSxBCI4aPbtWqTf/+g/E9OWAB0dHRCQkJ2dnZNVP4fP64ceOwhvoXSq0hX1VQkFdWVtqje5+aKZGRnauqqgoK8x48uOPIdyTaiBDy9PTy8wvIeJL20hI6dewmEDitWfvFzZt/N252YBVjx459ceTbkJCQ3r17Y030LxQvpFKlRAiJRC41UwQCJ4RQWelzpUopFDm/+GAnJ6G0rPSlJbi6irds2uXbxP/Tzz/68P+mlJY+b6zswCpiYmL8/PyIrx0cHMaPH4870b9Qs5A1l7q5u3kghGSy/90xt6KinKilm9hdLpe9OFd5udTRUfDq0vz8Ar5au+nb9dtycjK/+nq59eMD64qLiyNWkiEhIX369KnDHI2HaoXkcXkIobL/ruhcXcWeHl7JyddqHnD58p9cLjckpHmrVm0UCvnjx6nE9Kysp4WF+a1bhyGE2Cw2QqimrlqtFiHULjyyU6fuT56m43hawJJiYmICAgJ4PB7ZVo9U26mDEGoV2pbBYGzZun5QVLRGq4keFjtp4vR1Xy//Zv3KyMjOd+8m/33t0sQJH/B4vH59B+3bv3v5ikXx46fS6fRfftkhEjkPjx6FEAoMCqHT6Ru+Xztn9gIul/flikUxw0fzeA7JyddbNH8H91O0O1UKvSSrWiU3VMkNiIZUcgvcLqlf23nZgmxjSas/D5S85aKYLBqdQeMLmA5ODGd3tmfAW42fav5WAsmJ5Vo1atvLxdwsZPf7ud927PxBq9E0bdriu29/RAid/O3okaP7SkqKxK5u0dEj48ZMIK4WLy4u2rrtuzt3k4xGY5vW4bNnzffzCyAWcv78mZ8TdnTt0nNA/yE/bd/0+HGqyWRqG9Z+7pyF7u4euJ9i/Rj0pv1rs2ett7G7CWjVxpSrlZkPVPJyvYuPg9FIY7AYTDbLSLahN2jIpDcYdAajzoCQUV6qCQrlN2vPb9KM35CFUa+Q4CU2V0iTyXTjTPmDK5XiACe+s4ODyJbG7NZrDPLSKpNOY9Lpu49w9fCrX3iqbbICW5edqvpjX4nYT9iydwDuLA3B5DBcfAUICZTl1ed+LvVrzus9Slz32am2UwfYtFvnK26crWzW3c81QIQ7y9tydOH5t/dWVLET1ubVfS4oJCCLe5dkzzJ1Pq09yTkeXMM4ufNdg8VbP8k0Gur00RcKCUjhyq9lT1M14kBX3EEsjyfgtOjp/+Oi7Do8FgoJSCD9lkKSq3MPpmAbCXQGPTDC88D6/Dc/slHyAFArabEm9abSswXF7w7ME3Id3QTXTklf/zAoJMDs8jEpR0jGAeAsTuAueJykkEt1r3kMFBLgJMmqVlYaBG4OuIM0Erdg5yu/vm4lCYUEON2/KnMNIuP5J2XS/AVfdLyXct6yixV6OlapTGWSWgeagUICbDTVhrzHVXybOhHHAhjMnIe1jkAJhQTYZD9UCT3tZWO1hkDMf3q/1kJa5tS53xOPOYsou8+ahDgcdnhYF9wp3pYkR+Po2pAzsOvievKxy9f2y+TPXZzlUGO5AAANU0lEQVS9w9sM6NV1PIvFKZRkbNkxbUr8hrPnt0qKnziLvIYMmBPasgcxi1JVcfLshkfpV1hMTnBgeysF4wk5MhZdWalzFLFe/a5lCqnRVLds2dwiiwJ1wXPg4I5gAcU51S6BVink+YvbL1/b363zGA+3wOdlzy5dTSgry39v5HKEkE6nSTj0ecyQ+c4ir8SLP+0/8sXn80/y+SKdXvufPR9Kpfk9uo5zcfa6nnTMGsEIapVRUam3YiH79R3M59vFnmuSMBq1uCNYQLXSwGQzLL5Ymbz0wpU940aubBP6z2gAQoH42Kmvhg/+mPhvzJD5Ya37I4QG95+1cdvErNx7bVr1vnbzSFHx0w8mbm4W0gEhFNCk9debxlg8G4HFZahkBrPfskwhHflk3FFGYQw6uw6PIjudxsjkWL6QT7OSDQb9vqNL9x1d+t9pJoSQTPHPeEhs1j8jQTqLvBBCckUpQij18WUvjxCijQghOt3ywWow2IzqWi6zhsuvADZGgwmZELL0meRyRRlCaMr470TCf5394+riW1yS9eIUJoOFEDIaDQihSlmxj1cjfewyGRGq5QR6KCTAhstn6LUGFtfCf4Q8nhPxhbtbPa6odOQ7K1UVlk1SG6Pe4OBkfg0Mhz0ANjxHpl5j/qPU22gaFEGj0f5OOlwzRaN9882XfLya5xemPS99ZvE8r9JrDHwn829DsIYE2HgGcpXVeh6y8B5jsWuTbp3GXL1xcFfC/FYteyoUZdeSjk6J/87Xu8Vr5urdfcLt+2e37prRo3Ock0B8NyXRsqlexOLSnFyhkIBkfEO4d/5SOrlb/shH9KCPREL3v28eyci86SQQh77TS+j0hqtJxK6+0yZ8fzpxU+LF7SKhR+uWvZ5kJlk8GEKoqlLNoCEHgfnqwSBX1EfaQa50WuP2z3Pe6WOTY+c0WElmedNWzHZ9nM1+F9aQABsWmx7U2lFVXs134dX2mOOnvrmbcu7V6b5eLQqKzA9a/eG0HR7ugZYKefaPrdeTzZwkwGJydHrz54gv/eQMm13rCbo0oz6wlbC270IhAU7tegvP7H4e6OJT2wOi+kzr1c3M3amIO8mZneWNW6f10rPruE4RMa9O1+t1TKaZU20QQixWrZ+KKwoVTiK6s0eth5GhkAAn9yZcV0+WrFgl9DT/SZLPF/H5OEeg4zsI+Q61rtDq63lWefxnfq95ABz2AJj1HuWmkSlxp2gMlRJ5WC/n2nbnEKCQADOBM7NDP2FBSjHuINalKKsyVFV1jDK/L6cGFBLgFxDKb9bWQZJG2XtvqpWakoyy2A9r/ahcAwoJSKHDQOf2vQTFT16+YS4FqMqrJanPp66q045fKKRlZDx53KdfJHEnybpIz0ibPmP80OiecMPJGs3bO4ZG8p7dkVjjfDpcZCXyaqls8pd1PdaKp5DzPp6++Yf1r3mAVFq2ZOn8kpJG/Vzx8OH9L1csbti8uTlZXp7eL968/jXUavXSZQsG9B9y9HBiUGBIw34iJYV2EQ6Mdyt4IHmeKTUaSXbbuXqSl6iyrud7eJhGzn3zlmoNPIc9IiM7e3h4veYBd+/dSk9/5OHhWccFGgwGBoPx+ilvlHj+dH1nqZGdk+nr+7rd2S+6cyepuroqJmZ0HX9cA56L7fLw505aFnD/cuW133JdfB0dXfm2NUikWqlVlFYhvZbngEZ95OPkav5YZW0wFHJ8fEyhpGDNqg0Iod17fiwqljDojKt/X2QyWXNmL+jXd+CfF8599fVyGo02aEi3wYNjPpy9ACGUmHj60JFfCgryXF3EH3wwt3ev/jdv/r1i1adxYyae/+NMaGjbxQuXb/txY8aTNHd3zzt3kqZOmc3hcL9Zv+LMqSt0Oh0hFDd26MjYsSNjx06ZFhcWFpH68H5efm5wcLNP5n/h7x+4YePaM2dPsNnsQUO6LV70Zc8efev1pHJyMrU67cT3R5aXl/Xo3nfuhws5HI7Z2CdOHtm58weD0fD+lNFTJs/q2aNvTk7W1m3fpT564ODAHx49akL8VITQS89l0MDotLSHO3b+kPb4IYfDHTpkxLSpc6z2EuEX1lMU1lOUeqPy6T1F6v0SNz++0YgYLCaLyyLbmpNGQwadwaAz6LV6hExGrSG4Db9pO2d334aMpoehkOvWboqf+G5gYAix8ZacfP2T+V/Mmb3g2+9W7du/q1/fgf36Dvz1xKHu3XrHjZlAzHL4SMLen39avOjLduEdTv525KefNvXu1T87J1OtVnt5eif8/Gt1dTVCKDc3Kzc3e86sBYsXLtfpdAn7dgYGhhBtVCqVJSXFwcHNEEJlZaVyWeWqld9pddoVKxZv3vLN+m+2zpwx78zZExs3bG/ZolUDnlR2TmazZi2XLllbWJj/+ZJ5Hh5eE+Knmo0dM3xU8q3rbmL3eR99ihAqlBT830dTJ0yYtnLFt4/TU+cvmBnWtn2bNuEvPZfU1AcfL5gxftyUZcu+ynuWM/ejqdQuJCG0syi0s8hoNEkyq1Vyg0quNxqM1Uoj7lz/wmDRGAwaX8TlC5jOHiyR21sN5oChkLnPsvl8vqenF0KooDAvasDQrl17IoSCgpo+y8tBCOn1+szMjA+mfkg8XqFU7N7zY/z4qd279VYqlVlZTwICg4kOdO3Ss3//wQghHo9HTIkfNyUkpBlCiMPhZOdkBgc1JRaSk5OJEAoKDFGr1XK5LH78VDc3d4RQ374DjxzdhxDKyEij0+khwc1eDXzyt6N7f/7pxSnHj/5r/FyZXCaVlsWPm+Li4uri4tqrV/87d5NGjBhjNjZCKDv7aUT7TsTXu3Ztbdu2/cjYsQih8LAId3ePrOynbdqEv/Rctv1nY3h45IT4qXq9Pj3jkUDgZJ0Xh4zodJpvM1vaan0bGAqZnZ0ZEPDfP82spz26/TMSUUFhnl+TAITQ08wMvV7frFlLYnp6+iO1Wn302P4DB/bo9LrOnbov+mQZsT4cPOh/JxkqlIqystLw8MiaKTnZmZGjOxNfZ2U/dXNzFwpFj9MfsdlsH58mxHS5XCYUihBCj9NTQ0Kas1hmtviHR48cHj3yNc8oJzuTTqcH/nf3jMlkMhgMtcUm1tWB/y1n8q3rUybPrplRJqt0dnZ56blotdq0tIcikfOQYT30en3Tpi2+/mpLg373gOywFPIpsWtRpVIVlxQFBv3zd5yV+aR79z4IocePU5s08SdWejUOHThTra525DsSm6B6vT4vL/fFXZQ52ZlMJtPP75/9y9XV1UXFksD/Nj/10QNiezUnJzPAP4jYR2I0Gm/cvNqpYzfihzZrav4C1jeuIbOynvj7B3K5XKJv129cGTY01mzsmnU1EcxoNFZVVbm6/nPL66Tk6waDITws4qXnQvhiyZpmTVtyOByz7xqAGjAc9sjOySRWJtnZT+l0eoB/EFGw3GfZRMFksorKygpJUWGhpAAhFBLcjM1m79u/y2Q05uZmFxTmI4QKC/N1Ol3NegYhlJOb5ecXwGT+8xaj1WkRQtLyMoTQH3/+funSH8Tma3Z2JoPJrKysyM9/tvarZSqVcvToeIRQRWW5RFIglZaVlr58vsjw6JHHj55/8d9LD0h7/FCr0ZSUFD97lrNk6ceOjoJRI8eZjU08faFQJBI5I4TodHpwUNO//jqvVqtzc7O3/LB+3NjJQqHopefCZrObhjQ/cnSfSqWsqChPS3tozdcH4NTYhdRoNIWF+UTxiEMFxLG7vLxcvV5PrC179ezP5XInTordsWMLQsjZ2WXxoi//+PP3UWMGfblysU6rJeZ1dRUTW5uEnJzMmvUhQkjoJIwZPuqb9SvGx8dkZz9lMplBQU2Jh+m02gmTYmfOnqDX6b7fsEPoJEQIRQ8b+SgtZVz88KtXL9brGRmNxkdpKf36DZ4+c/yHcyd7enp/v2E7n883G5t4G3ox5yefLC0qKox5t++SpfNHxIyZOGHaq88FIbRo4XKZrHLi+7GzP5xEvE8BSrK7EQPeHTlg8aIvO0R2xhVg6gfvRUZ0nv7B3Eb7iaQdMQC8yjKfId+fMvqlKUajkU6jvzrk5o6fDmA8xl1ZWVFRUU7sOsJi05Zv5HLZiBhrDYkNbJ1lCrl75+E6PAq/7JxMDodT9xOALK5Fs3cmT5rp6Ai3XQDm2deIAe3CI8+dvYYxwIABQzD+dEB+cLUHACQChQSARKCQAJAIFBIAEoFCAkAiUEgASAQKCQCJQCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIuav9mBzacZXr2UEtolGQ54BDRkjFDQ+82tIgTOr9Fl1o4cBViEt0ui15BrLFNTGfCHdm3BosIKkClmZ1r+V+fsTA7KpdQ3pE8K9cozi99C0B5WlmnsXpB2jKDg8EiWZH+SK8OiG7Ol9Zduers4ebAYTdv/YGEW5TipR3zhdOmVVIIMBGzy24XWFRAjlPFLdv1xZnKNmMOEVtSXufly5VBsS5thlqBh3FlAPbyhkDU017BWwJTQaYnNho8b21LWQAIBGAG+iAJAIFBIAEoFCAkAiUEgASAQKCQCJQCEBIJH/B4W8dP+iCyDHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 실행 시간: 1.12초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    del graph_builder\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "def route_tools(state: TestState):\n",
    "    if isinstance(state, List):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\"):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in state: {state}\")\n",
    "    \n",
    "    print(f\"--> ai_message : {ai_message}\")\n",
    "\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "    \n",
    "graph_builder = StateGraph(TestState)\n",
    "\n",
    "# query -> retrieve_document -> eval document  response\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "# graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "# graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory\n",
    "    , interrupt_before=[\"tools\"]\n",
    ")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:57:40\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what time is it now\n",
      "--> chatbot messages : <class 'list'>\n",
      "--> chatbotmessages : [HumanMessage(content='where?', additional_kwargs={}, response_metadata={}, id='602a1a28-19e5-4280-9364-8be63d222429'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T04:47:38.948681777Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5116103347, 'load_duration': 4525813865, 'prompt_eval_count': 188, 'prompt_eval_duration': 330000000, 'eval_count': 21, 'eval_duration': 259000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': [{'function': {'name': 'tavily_search_results_json', 'arguments': {'query': 'where'}}}]}}, id='run-c293fa14-c783-4a7e-b6fa-5b8449e89cf1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'where'}, 'id': 'cf9a2c38-81a8-4a0a-8eeb-53f490e34651', 'type': 'tool_call'}], usage_metadata={'input_tokens': 188, 'output_tokens': 21, 'total_tokens': 209}), ToolMessage(content='[{\"url\": \"https://www.dictionary.com/e/where-vs-were/\", \"content\": \"\\\\u26a1 Quick summary. The word where (pronounced [ wair ]) is commonly used to ask about place or location (Where are you?) or indicate those things (I told him where I was).The word were (pronounced [ wur ]) is a past tense form of the irregular verb be that is used with plural subjects (The cupcakes were delicious) and the pronouns you and they regardless of whether they are singular or plural\"}, {\"url\": \"https://www.si.com/college/tennessee/football/college-football-playoff-rankings-and-seeding-revealed-where-is-tennessee-ranked-01jekfahq7rr\", \"content\": \"The final college football playoff rankings have been revealed. Where are the Tennessee Volunteers ranked? Conference championship weekend wrapped up on Saturday night as Clemson, Oregon, Georgia\"}, {\"url\": \"https://www.merriam-webster.com/dictionary/where\", \"content\": \"Word History\\\\nAdverb\\\\nMiddle English, from Old English hw\\\\u00c7\\\\u00a3r; akin to Old High German hw\\\\u00c4\\\\ufffdr where, Old English hw\\\\u00c4\\\\ufffd who\\\\n\\\\u00e2\\\\u20ac\\\\u201d more at who\\\\nAdverb\\\\nbefore the 12th century, in the meaning defined at sense 1a\\\\nConjunction\\\\n12th century, in the meaning defined at sense 1a\\\\nNoun\\\\n15th century, in the meaning defined at sense 1\\\\nPhrases Containing where\\\\nDictionary Entries Near where\\\\nwhen you come (right) down to it\\\\nwhere\\\\nwhereabouts\\\\nCite this Entry\\\\n\\\\u201cWhere.\\\\u201d where\\\\nadverb\\\\nwhere\\\\nconjunction\\\\nwhere\\\\nnoun\\\\nSynonyms\\\\nAdverb\\\\nNoun\\\\nExamples of where in a Sentence\\\\nThese examples are programmatically compiled from various online sources to illustrate current usage of the word \\'where.\\' Share\\\\nKids Definition\\\\nwhere\\\\nwhere\\\\nwhere\\\\nMore from Merriam-Webster on where\\\\nNglish: Translation of where for Spanish Speakers\\\\nBritannica English: Translation of where for Arabic Speakers\\\\nSubscribe to America\\'s largest dictionary and get thousands more definitions and advanced search\\\\u2014ad free!\\\\n Absent Letters That Are Heard Anyway\\\\nPopular in Wordplay\\\\nThe Words of the Week - Mar. 22\\\\n12 Words for Signs of Spring\\\\n9 Superb Owl Words\\\\n\\'Gaslighting,\\' \\'Woke,\\' \\'Democracy,\\' and Other Top Lookups\\\\nFan Favorites: Your Most Liked Words of the Day 2023\\\\nGames & Quizzes\\\\nLearn a new word every day. Popular in Grammar & Usage\\\\n8 Grammar Terms You Used to Know, But Forgot\\\\nHomophones, Homographs, and Homonyms\\\\nCommonly Misspelled Words\\\\nHow to Use Em Dashes (\\\\u00e2\\\\u20ac\\\\u201d), En Dashes (\\\\u00e2\\\\u20ac\\\\u201c) , and Hyphens (-)\\\\n\"}]', name='tavily_search_results_json', id='f6c1603b-e4e3-464c-9ea4-d691e5df1d59', tool_call_id='cf9a2c38-81a8-4a0a-8eeb-53f490e34651'), AIMessage(content='The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\\n\\nSome common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\\n\\nThe word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T04:51:07.454343456Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2987319958, 'load_duration': 62368245, 'prompt_eval_count': 739, 'prompt_eval_duration': 427000000, 'eval_count': 140, 'eval_duration': 2008000000, 'message': {'role': 'assistant', 'content': 'The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\\n\\nSome common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\\n\\nThe word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".', 'images': None, 'tool_calls': None}}, id='run-cbf213a2-34d7-426b-9823-c8de06f60ae7-0', usage_metadata={'input_tokens': 739, 'output_tokens': 140, 'total_tokens': 879}), HumanMessage(content='what time is it now', additional_kwargs={}, response_metadata={}, id='10a5b390-7737-43dc-9a8b-d386b58183f5')]\n",
      "--> TAVILY_API_KEY_6 : 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\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (63bbb5f8-c994-472e-b97f-e4028997ee33)\n",
      " Call ID: 63bbb5f8-c994-472e-b97f-e4028997ee33\n",
      "  Args:\n",
      "    query: current time\n",
      "Goodbye!\n",
      "⏳ 실행 시간: 15.43초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test1\"}}\n",
    "\n",
    "# stream_graph_updates 함수는 사용자의 입력을 받아 그래프를 통해 응답을 스트리밍하는 함수입니다\n",
    "def stream_graph_updates(user_input: str):\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# 메인 대화 루프입니다\n",
    "while True:\n",
    "        # 사용자로부터 입력을 받습니다\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # 종료 명령어를 확인합니다 (quit, exit, q)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 사용자 입력을 처리하여 응답을 생성합니다\n",
    "        stream_graph_updates(user_input)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stream_graph_updates 함수는 사용자의 입력을 받아 그래프를 통해 응답을 스트리밍하는 함수입니다\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # graph.stream()을 사용하여 사용자 입력을 그래프에 전달하고 응답을 스트리밍합니다\n",
    "    # {\"messages\": [(\"user\", user_input)]} 형태로 입력을 포맷팅합니다\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        # 각 이벤트에서 값을 추출하여 출력합니다\n",
    "        for value in event.values():\n",
    "            # Assistant: 프리픽스와 함께 메시지의 마지막 컨텐츠를 출력합니다\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 사용자 입력을 처리하여 응답을 생성합니다\n",
    "stream_graph_updates(\"너는 누구야?\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:53:08\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\n",
      "\n",
      "Some common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\n",
      "\n",
      "The word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next\n",
    "\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(existing_message.tool_calls)\n",
    "\n",
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:59:44\n",
      "{'configurable': {'thread_id': 'test1'}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (63bbb5f8-c994-472e-b97f-e4028997ee33)\n",
      " Call ID: 63bbb5f8-c994-472e-b97f-e4028997ee33\n",
      "  Args:\n",
      "    query: current time\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='8961f990-3d44-43de-a006-3c65df908a63', tool_call_id='63bbb5f8-c994-472e-b97f-e4028997ee33'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='49f8aec7-209a-446a-a45f-06e57340600c')]\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-11-28 15:05:20\n",
      "--> messages : <class 'list'>\n",
      "--> messages : [HumanMessage(content='현재 시간은?', additional_kwargs={}, response_metadata={}, id='da3b46ed-a651-45d4-a1e2-d64841f2bc5e')]\n",
      "--> chatbot : after llm.invoke : 현재 시간은 다음과 같습니다: [날짜, 시간 포맷팅 규칙에 따라 현재 날짜와 시간을 표시합니다]\n",
      "{'messages': [HumanMessage(content='현재 시간은?', additional_kwargs={}, response_metadata={}, id='da3b46ed-a651-45d4-a1e2-d64841f2bc5e'), AIMessage(content='현재 시간은 다음과 같습니다: [날짜, 시간 포맷팅 규칙에 따라 현재 날짜와 시간을 표시합니다]', additional_kwargs={}, response_metadata={}, id='f7ff2f24-6e70-4b00-abeb-e76ee07443f0')]}\n",
      "⏳ 실행 시간: 15.82초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=10)\n",
    "\n",
    "inputs = State(messages=\"현재 시간은?\")\n",
    "outputs = graph.invoke(inputs, config)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"langgraph-cli[inmem]\" python-dotenv\n",
    "!rm -rf langgraph-server\n",
    "!langgraph new langgraph-server --template react-agent-python\n",
    "!cp ../.env langgraph-server/.env\n",
    "!cd langgraph-server && pip install -q -e . && langgraph dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2' temperature=0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Annotated, Any, List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the weather\"\"\"\n",
    "    if location.lower() in [\"seoul\", \"inchen\"]:\n",
    "        return \"It's 20 degrees and foggy.\"\n",
    "    else :\n",
    "        return \"It's 100 degrees and sunny.\"\n",
    "    \n",
    "@tool\n",
    "def get_coolest_cities():\n",
    "    \"\"\"Get a list of coolest cities\"\"\"\n",
    "    return \"seoul, inchen\"\n",
    "\n",
    "tools = [get_coolest_cities, get_weather]\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "print(llm)\n",
    "model_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    \n",
    "def chatboat(state: State):\n",
    "    return {\n",
    "        \"messages\" : [llm.invoke(state[\"messages\"])]\n",
    "        }\n",
    "\n",
    "def file_uploader(state: State) -> Literal[\"chatboat\"]:\n",
    "    \n",
    "\n",
    "def should_continue(state: State) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"agent\", call_model)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.set_entry_point(\"agent\")\n",
    "graph_builder.set_finish_point(\"agent\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", should_continue)\n",
    "graph_builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content=\"It's 20 degrees and foggy.\", name='get_weather', tool_call_id='0f4b7edc-a1ea-4119-9776-e2f2c8d91038')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(\"What's the weather like in Seoul?\").tool_calls\n",
    "tool_node.invoke({\"messages\": [model_with_tools.invoke(\"What's the weather like in Seoul?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: It's 20 degrees and foggy.\n",
      "Assistant: The current weather in Seoul is 20 degrees Celsius with a thick layer of fog.\n",
      "goobye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User : \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"goobye!\")\n",
    "        break\n",
    "    \n",
    "    for event in graph.stream({\"messages\" : (\"user\", user_input)}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got What's the weather like in Seoul?\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the weather like in Seoul?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1940\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1939\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1940\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1942\u001b[0m     config,\n\u001b[1;32m   1943\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1944\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1945\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1946\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1947\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1949\u001b[0m ):\n\u001b[1;32m   1950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1951\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1660\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1661\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1662\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1663\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1664\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1665\u001b[0m         ):\n\u001b[1;32m   1666\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:176\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    175\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 176\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    178\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/write.py:96\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     89\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[1;32m     95\u001b[0m     ]\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_at_least_one_of\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/pregel/write.py:143\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    141\u001b[0m     tuples\u001b[38;5;241m.\u001b[39mappend((PUSH \u001b[38;5;28;01mif\u001b[39;00m FF_SEND_V2 \u001b[38;5;28;01melse\u001b[39;00m TASKS, w))\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ww \u001b[38;5;241m:=\u001b[39m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    144\u001b[0m         tuples\u001b[38;5;241m.\u001b[39mextend(ww)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "File \u001b[0;32m~/Works/knd/customAIService/.venv/lib/python3.10/site-packages/langgraph/graph/state.py:674\u001b[0m, in \u001b[0;36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m    671\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    672\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[1;32m    673\u001b[0m     )\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[0;31mInvalidUpdateError\u001b[0m: Expected dict, got What's the weather like in Seoul?\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE"
     ]
    }
   ],
   "source": [
    "graph.invoke(\"What's the weather like in Seoul?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
