{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-10 17:58:04\n",
      "⏳ 실행 시간: 20.19초\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain_community\n",
    "!pip install -q langchain-ollama\n",
    "!pip install -q langgraph langsmith \n",
    "!pip install -q tavily-python\n",
    "\n",
    "!pip install -q streamlit-chat\n",
    "!pip install -q faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:12:31\n",
      "--> TAVILY_API_KEY_4 : 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\n",
      "[{'url': 'https://www.geeksforgeeks.org/introduction-to-langchain/', 'content': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.'}, {'url': 'https://python.langchain.com/docs/introduction/', 'content': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}]\n",
      "⏳ 실행 시간: 2.48초\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "import os\n",
    "import random\n",
    "def get_tavily_api_key() -> str:\n",
    "    random_number = random.randint(1, 7)\n",
    "    # random_number = 7\n",
    "    print(f\"--> TAVILY_API_KEY_{random_number}\")\n",
    "    return os.getenv(f\"TAVILY_API_KEY_{random_number}\")\n",
    "\n",
    "def get_tavily_retriever() -> TavilySearchAPIRetriever:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = get_tavily_api_key()    \n",
    "    return TavilySearchAPIRetriever(k=2, api_key=get_tavily_api_key())\n",
    "\n",
    "def get_tavily_search_results() -> TavilySearchResults:    \n",
    "    os.environ[\"TAVILY_API_KEY\"] = get_tavily_api_key()\n",
    "    return TavilySearchResults(max_results=2)\n",
    "\n",
    "\n",
    "\n",
    "# result = get_tavily_search_results().invoke({'query':\"What is LangChain?\"})\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:47:27\n",
      "Name: llama3.2:latest\n",
      "Name: llama3.2-vision:latest\n",
      "Name: EEVE-Korean-Q5_K_M:latest\n",
      "⏳ 실행 시간: 0.09초\n"
     ]
    }
   ],
   "source": [
    "from ollama import list\n",
    "from ollama import ListResponse\n",
    "\n",
    "response: ListResponse = list()\n",
    "\n",
    "for model in response.models:\n",
    "  print('Name:', model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:47:29\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:52:30\n",
      "[HumanMessage(content='안녕하222세요?', additional_kwargs={}, response_metadata={}, id='1'), AIMessage(content='반갑습니다~', additional_kwargs={}, response_metadata={}, id='2')]\n",
      "⏳ 실행 시간: 0.03초\n"
     ]
    }
   ],
   "source": [
    "## test add_messages\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "# 기본 사용 예시\n",
    "msgs1 = [HumanMessage(content=\"안녕하세요?\", id=\"1\")]\n",
    "msgs2 = [AIMessage(content=\"반갑습니다~\", id=\"2\")]\n",
    "msgs3 = [HumanMessage(content=\"안녕하222세요?\", id=\"1\")]\n",
    "result1 = add_messages(msgs1, msgs2)\n",
    "result2 = add_messages(result1, msgs3)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "# llm = OllamaLLM(model=model_name)\n",
    "llm = ChatOllama(model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:16\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is an open-source project that aims to simplify interoperability between blockchain networks and traditional software applications. Here's a breakdown of what it does:\\n\\n1. **Layering**: LangChain introduces the concept of layering, where blockchain-specific functionality is integrated into existing software layers, making it easier for developers to incorporate blockchain capabilities into their projects.\\n\\n2. **Web3 Integration**: It provides an interface for interacting with Web3 applications (e.g., Ethers.js), allowing developers to access and manipulate blockchain data, perform transactions, and more within the context of their existing applications.\\n\\n3. **Decentralized Data Storage**: LangChain enables decentralized storage solutions like IPFS (InterPlanetary File System) or Swarm, which can be used for storing and retrieving data in a secure and decentralized manner.\\n\\n4. **Blockchain Network Agnostic**: It allows developers to easily switch between different blockchain networks without having to rewrite their code, making it easier to experiment with different networks and find the best fit for their project's needs.\\n\\n5. **High-Level Abstractions**: LangChain provides high-level abstractions for common blockchain-related tasks, such as token management, smart contract interactions, and more, making it easier for developers to build blockchain-enabled applications without having to delve into low-level details of blockchain protocols.\\n\\nBy simplifying the integration of blockchain capabilities into traditional software applications, LangChain aims to make blockchain development more accessible and user-friendly.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T02:53:28.106953433Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9018536368, 'load_duration': 4763800118, 'prompt_eval_count': 41, 'prompt_eval_duration': 383000000, 'eval_count': 286, 'eval_duration': 3869000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-2ae80a31-1e5b-4706-92be-b58c1b3366c1-0', usage_metadata={'input_tokens': 41, 'output_tokens': 286, 'total_tokens': 327})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 실행 시간: 9.26초\n"
     ]
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 10:58:44\n",
      "--> messages : [SystemMessage(content='answer is korean', additional_kwargs={}, response_metadata={}, id='1'), HumanMessage(content='현재 시간은!', additional_kwargs={}, response_metadata={}, id='2')]\n",
      "--> messages type : <class 'list'>\n",
      "⏳ 실행 시간: 2.41초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"answer is korean\", id=\"1\"),\n",
    "    HumanMessage(\"현재 시간은!\", id=\"2\"),\n",
    "]\n",
    "print(f\"--> messages : {messages}\")\n",
    "print(f\"--> messages type : {type(messages)}\")\n",
    "response = chain.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-11-28 15:09:35\n",
      "Step 1: Understand the context of the question.\n",
      "The given text appears to be a list of message objects, which consists of two messages - one labeled \"SystemMessage\" and another labeled \"HumanMessage.\" These messages are meant for processing by an AI assistant like myself.\n",
      "\n",
      "Step 2: Analyze the content of each message.\n",
      "- SystemMessage(content='answer is korrea', additional_kwargs={}, response_metadata={}, id='1'): This message has the content \"answer is korrea\" and no additional keywords or response metadata. We can assume that it's a question, but it may have some spelling mistakes.\n",
      "- HumanMessage(content='현재 시간은!' additional_kwargs={}, response_metadata={}, id='2'): This message simply states, \"현재 시간은!\" which translates to \"What time is it now?\" in English. It seems like a request for the current time.\n",
      "\n",
      "Step 3: Combine both messages for clarity and provide an answer.\n",
      "Since the first message appears to be a question but has spelling mistakes, we can assume that it's asking about the current time as well. The correct phrase should be \"What is the answer in Korea?\" or simply \"What's the time in Korea?\" Combining both messages, we can provide an answer:\n",
      "\n",
      "Answer: Based on your two messages, I understand you are interested in knowing the current time in Korea. As of now, it is [insert the current time in Korean Standard Time (KST) here].\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 11:53:39\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Any, List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class TestState(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "        #  messages: list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:24:57\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n",
    "def chatbot(state: TestState) -> TestState:\n",
    "    # print(f\"--> chatbot : start state: {state}\")\n",
    "    print(f\"--> chatbot messages : {type(state['messages'])}\")\n",
    "    print(f\"--> chatbotmessages : {state['messages']}\")\n",
    "    tools = [get_tavily_search_results()]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    # response = llm_with_tools.invoke(state['messages'])\n",
    "\n",
    "    # print(f\"--> chatbot : after chain.invoke : {response}\")\n",
    "    # # Create an AIMessage instead of returning raw response\n",
    "    # from langchain_core.messages import AIMessage\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 12:00:07\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A Node that runs requested in the last AI message\"\"\"\n",
    "\n",
    "    def __init__(self, tools: List[BaseTool]):\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs:dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            messages = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No messages found in inputs\")\n",
    "        \n",
    "        output = []\n",
    "        for tool_call in messages.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "                )\n",
    "            output.append(ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": output}\n",
    "    \n",
    "tool_node = BasicToolNode([get_tavily_search_results()])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def search_wikipedia(state: TestState) -> TestState:\n",
    "    # print(f\"--> chatbot : start state: {state}\")\n",
    "    print(f\"--> messages : {type(state['messages'])}\")\n",
    "    print(f\"--> messages : {state['messages']}\")\n",
    "\n",
    "    response = chain.invoke(state['messages'])\n",
    "\n",
    "    print(f\"--> chatbot : after chain.invoke : {response}\")\n",
    "    # Create an AIMessage instead of returning raw response\n",
    "    from langchain_core.messages import AIMessage\n",
    "    return {\"messages\": [AIMessage(content=str(response))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:46:59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAEjCAIAAAA628qRAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BPdkIICRA2sl0VFRTce+FELA6qotZRZ/3VatW2Vq27ra1WrfZbd4t7VOuo2GoddYAbEUFZMgIIAbIgO78/rl++VoMCJnwul/fz4R945I5XCK/c5cbnaCaTCQEAyIGOOwAA4H+gkACQCBQSABKBQgJAIlBIAEgECgkAiTBxB7BrBr3peZ5apTBUKfRGPdJqjLgT1QmbS+fy6Q4CpkDEdPZg445DKTQ4Dtn4tBpjxm1F9kNlYWa1VyCP60B3EDCFbixttW0U0mg0Kcr1VQo9h8coLdQEhvKDWvO9g3i4c1EBFLKxJf0uzX6o9ArkBbV29GvhgDvO26os1eakqqTFWmWFvsswV/cmXNyJbBsUsvFkPlD8kfC8fT/nDlEuuLNYXv6TquunpF5B3B4j3HBnsWFQyEZy86xUJdf3jHVjsqi8Iy3nkerK8dL3FvqxOVR+mtYDhWwMSb9L6Qxa5AAKrhhfJZfqDnydN3llIIsNnaw3KKTVnf+lWOjG6jjQFXeQRrX9s+zxn/nzHBm4g9gYeA+zrrsXK/hCpr21ESE0drHfga/zcKewPVBIK8rLUCnK9V2jxbiDYMB3Yg6I9/jrcAnuIDYGCmlFV46XtekuxJ0CG9+mDvJyfV56Fe4gtgQKaS2Pk+We/lw7P5Gl6zDxtVNluFPYEiiktWTeV3aNtruPji8R+3D8mztkpShxB7EZUEirKMqt1lQZeY6NdKpwUVGRRCLBNfvruTXhPL0HhawrKKRV5KSqAkP5jfOzCgoKoqOj09LSsMz+RoGh/JxUlZUWTj1QSKuQSrRBbRqpkHq9vmEHk4m5Gjx7HTFZ9JBwx/wn0Mk6gRMDrGLr/MzpXwczGDTLLlatVq9bt+7KlSsIofDw8AULFphMpujo6JoHDB06dPny5Vqtdvv27YmJiSUlJWKxeMiQIdOnT2cwGAih0aNHBwcHBwcHHzx4UK1W7969+7333ntpdstmRghdOvrc1ZPTupv97nCuO7ge0vKqVQY2l27xNiKEdu/effr06RkzZojF4tOnT/N4PAcHh1WrVi1ZsmTGjBkREREuLi4IIQaDkZSU1KNHD19f34yMjF27djk5OY0fP55YyI0bN9Rq9YYNG6qqqvz9/V+d3eL4TkyVXG+NJVMPFNLyqmR6B6FVfrESiYTH402aNInJZMbExBATW7RogRAKCAgICwsjpjAYjL1799Jo/7wjFBQUXLx4saaQTCZzzZo1PB6vttktji9kFmVXW2nhFAOfIS3PYDTxHKzyix00aJBarf7www8zMzNf/8jy8vJ169bFxMT06dMnKytLKpXWfCs0NLSmjY2DyaTRrLC9QElQSMvjOzErnuusseQuXbp8//33Uqk0Li5u1apVer357UCpVDpu3Ljk5OSZM2du3ry5ZcuWBoOh5ruN3EaEkKJSz+XBX1qdwCar5fGdmFUKQx0e2BBdunTp1KnTgQMHNmzY4OXlNWXKlFcfc+zYsfLy8j179nh6eiKEPD09nz17ZqU8daGS64UuLIwBbAi8b1lFwDsOykrLryS1Wi1CiE6njxs3zs3NLT09HSHE5XIRQqWlpTUPq6ysdHZ2JtpI/Pc1+9Jfnd3iaAg5ieGtv07g12QVAmdWdqqqTTeRZRd78ODBy5cvDx48uLS0tLS09J133kEIeXh4+Pj4JCQk8Hg8mUwWFxcXERFx+PDhbdu2tW3b9uLFi9euXTMajZWVlSKRmTyvzs7hcCwbO+VvmX1e8tIAsIa0CiudnuLr66vVajds2HDixIm4uLj4+HiEEI1GW7NmDZ/PX79+/alTp8rLy/v06TN16tQjR458/vnnOp1uz549AQEBhw4dMrvMV2e3bOZnj1VNmjnQYadO3cCJAdZyfHNBzGwfOt3e/xCTEqUCEfOdjnBWQJ3AJqu1+Lfk3zwr7TK01k21gQMHqtXqV6e3adMmJSXl1elCofDkyZOWjvmyLVu2HD169NXpAoFAoVCYneXPP/9kMs3/IVUp9Kl/y6esDLR0TMqCNaQV/fRp9sSl/hye+XFliouLjcZ6jIxMp9Nr9tNYj0wmU6nqt7Ht5eVVcxLCS/7cX+ITwmvZwclC6agPCmlF6bfksjJdx0F2elVkZan2xhnpoEleuIPYEtipY0UtIp1UcsOjGzLcQfA4+E1+v7EeuFPYGCikdfUZ4552U56bZncXHx1cnxczyweGZq0v2GRtDKe3S1p0EIS0FeAO0kgOfZs/cJKH0NWuxxNqGHgDawxDp3k/uaO8e7ECdxCrqyzV/rgwq2esG7SxYWAN2Xhu/1GeliTvMkwc0tYRdxbLq1Lor5+S6rTGfmM9YEu1waCQjUpWprt+qsxoRH7NHQJD+Y4iKhwHzkuvKs6tfnhN3mWYKxzheEtQSAyKn6nTb8lzUlUOjkyPAI6DgMl3YjiKmAZrXSJiYUa9UVGhV8kMJmR6+LfMJ4TXLFzQsiNU0QKgkDg9L1A/z9OoZHqV3MBg0pSVFh7nIj09vUmTJny+hYfb4jrQOQ4MvpAhdGX5t+QzmPZ+eqAFQSGpbNKkSfPnz2/dujXuIKCu4MM3ACQChQSARKCQVNakSRM6HV5iWwKvFpXl5+fX64ISgB0UksocHR1ruzAKkBMUksqUSiXsRbctUEgqc3FxgTWkbYFCUll5eTmsIW0LFJLK/P39YS+rbYFXi8qePXsGe1ltCxQSABKBQlKZkxNcgWFjoJBUJpfLcUcA9QOFpDKhUAiHPWwLFJLKZDIZHPawLVBIAEgECkllXl5ecBzStsCrRWVFRUVwHNK2QCEBIBEoJJX5+fnBJqttgVeLyvLy8mCT1bZAIQEgESgklQUEBMAmq22BV4vKcnNzYZPVtkAhASARKCSVwTCQNgdeLSqDYSBtDhQSABKBQlIZjMtqc6CQVAbjstocKCSVeXt7w04d2wKvFpVJJBLYqWNboJAAkAgUksqcnZ1hp45tgUJSWUVFBezUsS1QSCqDWwnYHHi1qAxuJWBzoJBUBmtImwOvFpXBGtLmQCGpzM3NDfay2hYa7IWjnqioKDabTaPRysvL+Xw+8TWbzT569CjuaOANmLgDAMvj8/l5eXnE12q1mvhi1qxZWEOBOoFNVgoaMGDAS1P8/Pzee+89THFAPUAhKWjUqFF+fn41/2UwGMOHD+fxeFhDgTqBQlKQq6trv379av7r7+8/cuRIrIlAXUEhqWn06NH+/v7E6nHIkCF8Ph93IlAnUEhqEovFffr0odFofn5+sHq0IbCXtZHotcbyEq1KZmi0o0xdw9+9dTmve/fuJTkIIVXj/FAmi+bqxeY7wd9VA8FxyMaQ9Lv0yT0lk0UXill6LZV/4Q5OjGdpKg9/bq+Rbo4iqGW9QSGt7vKxUkSjt+vrijtI46l4rrlypHjEbB++EDpZP/AZ0rqu/VZGZ9hXGxFCzu6codP99q7MxR3E9kAhrUhRqSt5pg7rbV9tJDCYtA6D3JITpbiD2BgopBVVFOtodPs9t1vgzJJkq3GnsDFQSCtSVOicPbi4U2AjcGEZ9LhD2BoopBWZTEirNuBOgY3JhFQyaGT9QCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIlBIAEgECgkAiUAhASARKCQAJAKFBIBEoJC2YdjwXtt+3FjfuYqLi4qKJTX/PXpsf+++EVVVVfVdTtrjVI1GU9+5QANAISmrUFIwdnx0RkbaWy7nXOKp2XMmqdXVFsoFXgcKSVkGvd4i47PAurExwZAnpHP295PHfz2Yl5fr6Cjo0rnHlMmznJ1dEEJKpWL12i+uXbskdBLFxU0cHj0SIaTVan/+ZfvFi4nPS0tcXcUD+g+ZNHE6g8EoKpZMfH8kQujLFYu/RCgqaujihcuJ5e/YueXK1YvV1VUR7TvNmvmxh4cnMT3tceqP/9mYkZHG5fK6dO4xc+Y8J4HTucRTG79fhxCKebcfQmjRwmUDo4Zh/fVQHBSSXPbs/c/en7f36tlvVOy4isryW7duMFks4lu/n/stasDQeR99dvGvxI3frwsMCG7TJpzBYNy5k9S5Sw9vL9/MzIyEfbsEAqfRo8a7uog//2zV6jVL3p80Izwsgqg0obT0+bQpc7JzMn89cSjjSdr2nw4IHAW5udnzF8wICAhe+MkyWWXF7j0/Pn9e/O36bR07dB09avzhIwlrV2/k8x19ff1qzw4sAApJIlJpWcK+Xf37D/5s8QpiStyYCTXfHdB/yKKFyxBC3bv1Hj1m0KXLfxCF3PrD3pqbQEqKCq5cvTh61Hg2m92saQuEkJ9fQOvWYS/+lE8Xr3BwcEAIhbVt/9mSecePH5w4YVrCvp10Ov3rr7YIHAUIIYHAac26pQ8e3G3btp23ty9CqGXLUKFQ1Li/D3sEhSSRByl3DQbD8GHmBxqv6QOXy/X29n1eWkL8t6Ki/Odftt+6fVOhkCOEiEbVRefO3T09vO7fvz1xwrT7D+6Eh0fWzBsZ2RkhlPEkrW3bdpZ4ZqCuoJAkUllZgRByc/N44yPpDIbBYEAIlZdLP5gxjsdzmPz+TG9v3127tuYXPKv7TxS7uatUSoSQSqUUCZ1rpgsETgihsrLShj4V0EBQSBJx5DsihMorpO7ub+4k4bdTxyoqyn/YvIfYN+Pu7lmvQlZUlPt4+yKExGJ3uVz24nSEkOMLK1sYULtxwGEPEmkV2hYhdPbsiZopev0bBomSyytFIueaPaUyeWVNczgcLkJIWvta7mlmRmFhfrt2HRBCrVq1uf/gTs3tlq9cuYAQIj588rg8WFs2GlhDkoiPt+/QISNOnT4ul8siIzvLZJWnTh377rv/eHl61zZLWFjErycO79q9rVWrtlevXkxKumY0GmWySqFQ5O7u4e3lc/hoApfHk8tl746II2ZZvXZJj259ioolv5445O3lM3TIuwih8WMnX7yYuOjTD4cNjX3+vHjvzz+Fh0WEtW1PvE0wGIwtW9cPiorWaDXRw2Ib8VdidxjLly/HnYGynudrFBWGJs3rcW/GTh27sdnsGzeuXPzrfGFBXmRk5/CwCD6ff+DgnqZNW0RGdCIedubsCS6X26/vQH//QJPJeOLkkatXLnj7NFkw/4uHD+9VV1eFhUXQaLR33mmTfOv6xb8Si4ol3br2zsvPdeQ7stmcEycPp6WlRER0WvL5amdnZ4SQk5OwdWj4rds3Tp0+lvHkce9eAz5ZsJTD4SCEnARObm4ely79cePGVYVCHhU1tI7PRVNtzHmoaNsD9s3WA9xsx4pSr8sk2ZrOw9xxB8FDXq67sE8yYYk/7iC2BD5DAkAiUEgASAQKCQCJQCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIlBIAEgECgkAiUAhASARKCQAJAKFtCI2l851YOBOgY3JaHLxYuNOYWOgkFbk7M4uyFThToFNmUTDZtNwp7AxUEgrcvPlcLh0TbUBdxA8yiVqBzcl7hQ2BgppXd1ixH/uk9ThgVRz7y+pyWjKKLw8ffp0rVaLO47NgBEDrE5apDmysaDDQLGTK9tRxESIyltxRqOptEAtlaiR0dQnzh0hdPv27YCAACaTKZVKg4ODcQckOyikFV24cGH//v07d+7Uaoy3E8slOWqt2qhVGxstgFqtZrFYDEbj7VgS+3CZLBTcht80/F/jNWs0mvj4+BEjRrz33nuNFsYmmYAVyGQyk8n01VdfVVVV4cpw69atqKioxYsX4wrwqnv37plMpsTExIqKCtxZSAo+Q1remjVr7t27hxBauHAhj8fDFeOXX34pLS1NTU19+PAhrgwvCQsLQwh5eXnFxsZKpVLYOnsVFNLCzp0717x58549e+KNkZycnJ6eTqPRioqK9u/fjzfMS1q3bn3hwgUGg5GUlLRjxw7cccgFCmkZubm5CxcuRAgNHDgwNhb/UMIJCQllZWXE1w8fPkxNTcWd6GUikahTp046ne7YsWO4s5AIFPJtVVdXI4SuXr06d+5c3Fn+kZycnJGRUXOPuqKiooSEBNyhzJs5c+bw4cMRQosXL7506RLuOPhBId/Knj17lixZghCKj4/39fXFHecfu3fvlkqlNf+l0WipqakpKSlYQ9WKyWQihBYsWHDq1Kni4uI33s6E2qCQDaTX6+VyuUKh+Pbbb3FneVl6evpL++6Kior27NmDO9friMXib7/9ViQSKZXKlStXGo2Nd3CIVOA4ZL0ZjcYvvvhiyZIlHA6HTif1O9rEiRM/+eST0NBQ3EHq58SJEzk5OfPmzcMdBAO4+1W9ff/99927d8d4PKPuvL292Wzbu94iJiaG+GLFihVjxoxp3rw57kSNh9Rv8KRSWlq6bt06hNC8efMGDhyIO06dZGdnk3wd/nqTJ09evXo17hSNyoZfrUY2e/bskSNH4k5RPywWi8+vx83wyMbX1/fnn38mToi9f/8+7jiNAQr5BgUFBUlJSQihw4cPh4SE4I5TPzk5OcTtH21d27ZtN2/efOfOHdxBrA4K+To5OTmzZ89u1aoV7iANoVAovLy8uFwu7iAWwGKxdu7cSaztCwoKcMexIiikeWq1mrhG4eTJk46OjrjjNER+fr5N7HmquxYtWhCnEBDbLJQEhTQjLS0tKiqq5i/ARpWUlLRv3x53CstLSEiQSCh7zTcU0ox79+5dvnwZd4q3dfv2bU9PT9wprGLEiBEIoSVLlsjlctxZLAwK+T8Gg4HYyT5u3DjcWSxAIpHY3CkB9fLxxx9/9NFHuFNYGBTyfz744IP4+HjcKSxDqVTevXuX2oV0cXHZtWsXQohKe1+hkAghRFydtHPnTj8/P9xZLOPvv//u1q0b7hSNhITXfDYYFBLt3bs3NzcXdwoLS09P79+/P+4UjWTo0KE2fULSiyjyNN6GWq0eOnQo7hSWpFKpjh8/3qtXL9xBGk9cXFxZWVl2djbuIG/LrgtZUlIik8mmT5+OO4iFnThxoub8bPshFotTUlJWrlyJO8hbsd/Lr7755psmTZrExcXhDmJ506dPX7Zsmbe3N+4gGFRWVmo0Gg8PD9xBGshOCymVShkMhkgkwh3E8k6ePPngwYOlS5fiDoJNdnY2jUYLDAzEHaQh7HGTtaKiQqlUUrKNCKGtW7fOmjULdwqcgoKCfvrpp/Pnz+MO0hB2t4aUyWQjRoy4ePEi7iBWsXfvXqVSOXv2bNxB8MvNzfXy8uJwOLiD1I/dFfLcuXMRERFisRh3EMsrLS2Nj48/d+4c7iCkYDQaU1NT27RpgztI/djdJuvAgQMp2UaE0OrVq219H6MF0en04uLiTz/9FHeQ+rGvQo4ZM0ahUOBOYRUHDx708fGJjIzEHYREBgwYMGbMmMLCQtxB6sGOBrlKTEzs16+fQCCow2NtTGZm5q+//nro0CHcQUiHuJuIDbG7z5CUNGHChA0bNri6uuIOQkanTp0qLCycMWMG7iB1Yi+brGq1Oi8vD3cKq5g7d+706dOhjbUZNmzYnTt3iouLcQepE3tZQ+7du1cmk5Hn9huWsmnTJqFQOHHiRNxBgGXYyxpSp9MNGDAAdwoLu3DhgsFggDbWxc2bN1UqFe4Ub2Yva0jquXfv3g8//AD3V6yjY8eOZWRkfPbZZ7iDvIFdrCENBsONGzdwp7CkwsLCZcuWQRvrLjY21sPDw2Aw4A7yBnaxhiwrKxs3blxiYiLuIJah0+nmzp27bds23EGA5dnFGhIh1Lt3b9wRLKZbt26bN2/GncL2FBcXf/fdd7hTvIFdFFIsFi9evBh3Csvo3bv3H3/8QdzkFNSLp6fnzZs3s7KycAd5HbvYZNXpdA8ePIiIiMAd5G0NGjQoISEBDjk2GHE0kszD1dpFIRFCXbp0+euvv2zuYpwXRUVF7du3j6pnxgOCXWyyIoS4XO67774bFRXVqVOnMWPG4I5Tb5MnTz558iS08e3NmTOnsrISd4paUfyjCHFzCxqNhhAihp03mUzEfTtsSM+ePc+cOUON+1hh5+Licu3atSFDhuAOYh7F15DdunUj2ljDzc2tS5cu+BLVj06nmzFjxpkzZ2z0DlwktHDhwo4dO+JOUSuKf4asrKwcP358zYnFJpMpNDR07969uHPViUwmi4qKunr1KovFwp0FNBKKryFFItGcOXMcHBxqptjK8MFFRUXz58+/efMmtNHiYmNjlUol7hTmUbyQxJgdXbt2JTYEbGV7NTMzc9q0aXBmnJV4eHg8evQIdwrzKL7JStDpdKNGjSooKGjZsuUvv/yCO84bpKSkrF69Gi7/tx69Xk+j0RgMBu4gZtRpL6teZ6xWGq0fxnpoc2ct+vrrr/v0GKKo0OMO8zq5ubk/bNm148d9b5mTRkOOIorvQm8wOp1uNJL07/kNa8jHyfKUq7LyYi3PkYxvJ9Sj1WrZbPbbL0fszZHkVDcLF/SMFdPotDrMYUdSUlI2bNiwe/du3EHMeN2baPL58jKJrvu7ngIX2K9gezTVBqlE/cP8rA/WBbE51N9ZUHc+Pj6kHYqu1jVk0rlyuVTfaah7o0cClqTTGg+vz5nxVTDuIOSiVCrJeWjX/BtnxXNtWaEG2kgBLDa9yzC3G6fLcAchF3K2sdZClhVqTCb44EERTq7sZ+nVuFOQy6JFi1JSUnCnMMN8IZUyg1sTOHOSIpw9uSw2fIb8F+JGA7hTmGF+p45OY9SpGz0LsA6T0VSSBy/nvyxdupROJ+ObFByqAvaIx+PhjmAeGd8kALC2vXv3btq0CXcKM6CQwB45ODhUVVXhTmEGbLICezRy5EhynsUNhQT2iEajvXTlOknAJiuwR7dv34bPkACQhUqlys3NxZ3CDNhkBfaoffv2QUFBuFOYAYUE9sjR0ZGcp7PCJiuwR7du3VqzZg3uFGZAIYE9otFo5Lx/KwULmfY4VaPRvM0SLl3+s3ffiLw8Mn7oBxYRERGxevVq3CnMoFohzyWemj1nkloNVxuB19HpdMRI9mRDtUK+5boR2Inbt2+T8/bmlNrLei7x1Mbv1yGEYt7thxBatHDZwKhhCKHz58/sO7BbIilwdRUPGTxi3Nj3iUtvpNKybT9uSEq+ptfrW4eGzZj+UVBQyKuL3X9gz4mThxUKeUhI80kTp7dv1wHHkwMWMHz48Pz8fOLVN5lM7du3p9FoJpPpzp07uKP9g1JryI4duo4eNR4htHb1xk0bd3Ts0BUhlJh4eu1Xy5o2bfHFkjW9evbftXvbvv27EUJqtfrjBTPu3E3+YNrcjz/6rExa+vGCGQql4qVl3rmbvH3HljZt2n380WeeHl7VpDwjGdTRlClTai68Is6eM5lM4eHhuHP9D6XWkM7OLt7evgihli1DhUIR8S64Y9cPrVuHLflsFUKoR/c+CoX84KG9se++d+Hiuby83G/Xb2sXHokQat06fOz46OPHD06cMO3FZRYXSxBCI4aPbtWqTf/+g/E9OWAB0dHRCQkJ2dnZNVP4fP64ceOwhvoXSq0hX1VQkFdWVtqje5+aKZGRnauqqgoK8x48uOPIdyTaiBDy9PTy8wvIeJL20hI6dewmEDitWfvFzZt/N252YBVjx459ceTbkJCQ3r17Y030LxQvpFKlRAiJRC41UwQCJ4RQWelzpUopFDm/+GAnJ6G0rPSlJbi6irds2uXbxP/Tzz/68P+mlJY+b6zswCpiYmL8/PyIrx0cHMaPH4870b9Qs5A1l7q5u3kghGSy/90xt6KinKilm9hdLpe9OFd5udTRUfDq0vz8Ar5au+nb9dtycjK/+nq59eMD64qLiyNWkiEhIX369KnDHI2HaoXkcXkIobL/ruhcXcWeHl7JyddqHnD58p9cLjckpHmrVm0UCvnjx6nE9Kysp4WF+a1bhyGE2Cw2QqimrlqtFiHULjyyU6fuT56m43hawJJiYmICAgJ4PB7ZVo9U26mDEGoV2pbBYGzZun5QVLRGq4keFjtp4vR1Xy//Zv3KyMjOd+8m/33t0sQJH/B4vH59B+3bv3v5ikXx46fS6fRfftkhEjkPjx6FEAoMCqHT6Ru+Xztn9gIul/flikUxw0fzeA7JyddbNH8H91O0O1UKvSSrWiU3VMkNiIZUcgvcLqlf23nZgmxjSas/D5S85aKYLBqdQeMLmA5ODGd3tmfAW42fav5WAsmJ5Vo1atvLxdwsZPf7ud927PxBq9E0bdriu29/RAid/O3okaP7SkqKxK5u0dEj48ZMIK4WLy4u2rrtuzt3k4xGY5vW4bNnzffzCyAWcv78mZ8TdnTt0nNA/yE/bd/0+HGqyWRqG9Z+7pyF7u4euJ9i/Rj0pv1rs2ett7G7CWjVxpSrlZkPVPJyvYuPg9FIY7AYTDbLSLahN2jIpDcYdAajzoCQUV6qCQrlN2vPb9KM35CFUa+Q4CU2V0iTyXTjTPmDK5XiACe+s4ODyJbG7NZrDPLSKpNOY9Lpu49w9fCrX3iqbbICW5edqvpjX4nYT9iydwDuLA3B5DBcfAUICZTl1ed+LvVrzus9Slz32am2UwfYtFvnK26crWzW3c81QIQ7y9tydOH5t/dWVLET1ubVfS4oJCCLe5dkzzJ1Pq09yTkeXMM4ufNdg8VbP8k0Gur00RcKCUjhyq9lT1M14kBX3EEsjyfgtOjp/+Oi7Do8FgoJSCD9lkKSq3MPpmAbCXQGPTDC88D6/Dc/slHyAFArabEm9abSswXF7w7ME3Id3QTXTklf/zAoJMDs8jEpR0jGAeAsTuAueJykkEt1r3kMFBLgJMmqVlYaBG4OuIM0Erdg5yu/vm4lCYUEON2/KnMNIuP5J2XS/AVfdLyXct6yixV6OlapTGWSWgeagUICbDTVhrzHVXybOhHHAhjMnIe1jkAJhQTYZD9UCT3tZWO1hkDMf3q/1kJa5tS53xOPOYsou8+ahDgcdnhYF9wp3pYkR+Po2pAzsOvievKxy9f2y+TPXZzlUGO5AAANU0lEQVS9w9sM6NV1PIvFKZRkbNkxbUr8hrPnt0qKnziLvIYMmBPasgcxi1JVcfLshkfpV1hMTnBgeysF4wk5MhZdWalzFLFe/a5lCqnRVLds2dwiiwJ1wXPg4I5gAcU51S6BVink+YvbL1/b363zGA+3wOdlzy5dTSgry39v5HKEkE6nSTj0ecyQ+c4ir8SLP+0/8sXn80/y+SKdXvufPR9Kpfk9uo5zcfa6nnTMGsEIapVRUam3YiH79R3M59vFnmuSMBq1uCNYQLXSwGQzLL5Ymbz0wpU940aubBP6z2gAQoH42Kmvhg/+mPhvzJD5Ya37I4QG95+1cdvErNx7bVr1vnbzSFHx0w8mbm4W0gEhFNCk9debxlg8G4HFZahkBrPfskwhHflk3FFGYQw6uw6PIjudxsjkWL6QT7OSDQb9vqNL9x1d+t9pJoSQTPHPeEhs1j8jQTqLvBBCckUpQij18WUvjxCijQghOt3ywWow2IzqWi6zhsuvADZGgwmZELL0meRyRRlCaMr470TCf5394+riW1yS9eIUJoOFEDIaDQihSlmxj1cjfewyGRGq5QR6KCTAhstn6LUGFtfCf4Q8nhPxhbtbPa6odOQ7K1UVlk1SG6Pe4OBkfg0Mhz0ANjxHpl5j/qPU22gaFEGj0f5OOlwzRaN9882XfLya5xemPS99ZvE8r9JrDHwn829DsIYE2HgGcpXVeh6y8B5jsWuTbp3GXL1xcFfC/FYteyoUZdeSjk6J/87Xu8Vr5urdfcLt+2e37prRo3Ock0B8NyXRsqlexOLSnFyhkIBkfEO4d/5SOrlb/shH9KCPREL3v28eyci86SQQh77TS+j0hqtJxK6+0yZ8fzpxU+LF7SKhR+uWvZ5kJlk8GEKoqlLNoCEHgfnqwSBX1EfaQa50WuP2z3Pe6WOTY+c0WElmedNWzHZ9nM1+F9aQABsWmx7U2lFVXs134dX2mOOnvrmbcu7V6b5eLQqKzA9a/eG0HR7ugZYKefaPrdeTzZwkwGJydHrz54gv/eQMm13rCbo0oz6wlbC270IhAU7tegvP7H4e6OJT2wOi+kzr1c3M3amIO8mZneWNW6f10rPruE4RMa9O1+t1TKaZU20QQixWrZ+KKwoVTiK6s0eth5GhkAAn9yZcV0+WrFgl9DT/SZLPF/H5OEeg4zsI+Q61rtDq63lWefxnfq95ABz2AJj1HuWmkSlxp2gMlRJ5WC/n2nbnEKCQADOBM7NDP2FBSjHuINalKKsyVFV1jDK/L6cGFBLgFxDKb9bWQZJG2XtvqpWakoyy2A9r/ahcAwoJSKHDQOf2vQTFT16+YS4FqMqrJanPp66q045fKKRlZDx53KdfJHEnybpIz0ibPmP80OiecMPJGs3bO4ZG8p7dkVjjfDpcZCXyaqls8pd1PdaKp5DzPp6++Yf1r3mAVFq2ZOn8kpJG/Vzx8OH9L1csbti8uTlZXp7eL968/jXUavXSZQsG9B9y9HBiUGBIw34iJYV2EQ6Mdyt4IHmeKTUaSXbbuXqSl6iyrud7eJhGzn3zlmoNPIc9IiM7e3h4veYBd+/dSk9/5OHhWccFGgwGBoPx+ilvlHj+dH1nqZGdk+nr+7rd2S+6cyepuroqJmZ0HX9cA56L7fLw505aFnD/cuW133JdfB0dXfm2NUikWqlVlFYhvZbngEZ95OPkav5YZW0wFHJ8fEyhpGDNqg0Iod17fiwqljDojKt/X2QyWXNmL+jXd+CfF8599fVyGo02aEi3wYNjPpy9ACGUmHj60JFfCgryXF3EH3wwt3ev/jdv/r1i1adxYyae/+NMaGjbxQuXb/txY8aTNHd3zzt3kqZOmc3hcL9Zv+LMqSt0Oh0hFDd26MjYsSNjx06ZFhcWFpH68H5efm5wcLNP5n/h7x+4YePaM2dPsNnsQUO6LV70Zc8efev1pHJyMrU67cT3R5aXl/Xo3nfuhws5HI7Z2CdOHtm58weD0fD+lNFTJs/q2aNvTk7W1m3fpT564ODAHx49akL8VITQS89l0MDotLSHO3b+kPb4IYfDHTpkxLSpc6z2EuEX1lMU1lOUeqPy6T1F6v0SNz++0YgYLCaLyyLbmpNGQwadwaAz6LV6hExGrSG4Db9pO2d334aMpoehkOvWboqf+G5gYAix8ZacfP2T+V/Mmb3g2+9W7du/q1/fgf36Dvz1xKHu3XrHjZlAzHL4SMLen39avOjLduEdTv525KefNvXu1T87J1OtVnt5eif8/Gt1dTVCKDc3Kzc3e86sBYsXLtfpdAn7dgYGhhBtVCqVJSXFwcHNEEJlZaVyWeWqld9pddoVKxZv3vLN+m+2zpwx78zZExs3bG/ZolUDnlR2TmazZi2XLllbWJj/+ZJ5Hh5eE+Knmo0dM3xU8q3rbmL3eR99ihAqlBT830dTJ0yYtnLFt4/TU+cvmBnWtn2bNuEvPZfU1AcfL5gxftyUZcu+ynuWM/ejqdQuJCG0syi0s8hoNEkyq1Vyg0quNxqM1Uoj7lz/wmDRGAwaX8TlC5jOHiyR21sN5oChkLnPsvl8vqenF0KooDAvasDQrl17IoSCgpo+y8tBCOn1+szMjA+mfkg8XqFU7N7zY/z4qd279VYqlVlZTwICg4kOdO3Ss3//wQghHo9HTIkfNyUkpBlCiMPhZOdkBgc1JRaSk5OJEAoKDFGr1XK5LH78VDc3d4RQ374DjxzdhxDKyEij0+khwc1eDXzyt6N7f/7pxSnHj/5r/FyZXCaVlsWPm+Li4uri4tqrV/87d5NGjBhjNjZCKDv7aUT7TsTXu3Ztbdu2/cjYsQih8LAId3ePrOynbdqEv/Rctv1nY3h45IT4qXq9Pj3jkUDgZJ0Xh4zodJpvM1vaan0bGAqZnZ0ZEPDfP82spz26/TMSUUFhnl+TAITQ08wMvV7frFlLYnp6+iO1Wn302P4DB/bo9LrOnbov+mQZsT4cPOh/JxkqlIqystLw8MiaKTnZmZGjOxNfZ2U/dXNzFwpFj9MfsdlsH58mxHS5XCYUihBCj9NTQ0Kas1hmtviHR48cHj3yNc8oJzuTTqcH/nf3jMlkMhgMtcUm1tWB/y1n8q3rUybPrplRJqt0dnZ56blotdq0tIcikfOQYT30en3Tpi2+/mpLg373gOywFPIpsWtRpVIVlxQFBv3zd5yV+aR79z4IocePU5s08SdWejUOHThTra525DsSm6B6vT4vL/fFXZQ52ZlMJtPP75/9y9XV1UXFksD/Nj/10QNiezUnJzPAP4jYR2I0Gm/cvNqpYzfihzZrav4C1jeuIbOynvj7B3K5XKJv129cGTY01mzsmnU1EcxoNFZVVbm6/nPL66Tk6waDITws4qXnQvhiyZpmTVtyOByz7xqAGjAc9sjOySRWJtnZT+l0eoB/EFGw3GfZRMFksorKygpJUWGhpAAhFBLcjM1m79u/y2Q05uZmFxTmI4QKC/N1Ol3NegYhlJOb5ecXwGT+8xaj1WkRQtLyMoTQH3/+funSH8Tma3Z2JoPJrKysyM9/tvarZSqVcvToeIRQRWW5RFIglZaVlr58vsjw6JHHj55/8d9LD0h7/FCr0ZSUFD97lrNk6ceOjoJRI8eZjU08faFQJBI5I4TodHpwUNO//jqvVqtzc7O3/LB+3NjJQqHopefCZrObhjQ/cnSfSqWsqChPS3tozdcH4NTYhdRoNIWF+UTxiEMFxLG7vLxcvV5PrC179ezP5XInTordsWMLQsjZ2WXxoi//+PP3UWMGfblysU6rJeZ1dRUTW5uEnJzMmvUhQkjoJIwZPuqb9SvGx8dkZz9lMplBQU2Jh+m02gmTYmfOnqDX6b7fsEPoJEQIRQ8b+SgtZVz88KtXL9brGRmNxkdpKf36DZ4+c/yHcyd7enp/v2E7n883G5t4G3ox5yefLC0qKox5t++SpfNHxIyZOGHaq88FIbRo4XKZrHLi+7GzP5xEvE8BSrK7EQPeHTlg8aIvO0R2xhVg6gfvRUZ0nv7B3Eb7iaQdMQC8yjKfId+fMvqlKUajkU6jvzrk5o6fDmA8xl1ZWVFRUU7sOsJi05Zv5HLZiBhrDYkNbJ1lCrl75+E6PAq/7JxMDodT9xOALK5Fs3cmT5rp6Ai3XQDm2deIAe3CI8+dvYYxwIABQzD+dEB+cLUHACQChQSARKCQAJAIFBIAEoFCAkAiUEgASAQKCQCJQCEBIBEoJAAkAoUEgESgkACQCBQSABKBQgJAIuav9mBzacZXr2UEtolGQ54BDRkjFDQ+82tIgTOr9Fl1o4cBViEt0ui15BrLFNTGfCHdm3BosIKkClmZ1r+V+fsTA7KpdQ3pE8K9cozi99C0B5WlmnsXpB2jKDg8EiWZH+SK8OiG7Ol9Zduers4ebAYTdv/YGEW5TipR3zhdOmVVIIMBGzy24XWFRAjlPFLdv1xZnKNmMOEVtSXufly5VBsS5thlqBh3FlAPbyhkDU017BWwJTQaYnNho8b21LWQAIBGAG+iAJAIFBIAEoFCAkAiUEgASAQKCQCJQCEBIJH/B4W8dP+iCyDHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 실행 시간: 1.12초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    del graph_builder\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "def route_tools(state: TestState):\n",
    "    if isinstance(state, List):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\"):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in state: {state}\")\n",
    "    \n",
    "    print(f\"--> ai_message : {ai_message}\")\n",
    "\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "    \n",
    "graph_builder = StateGraph(TestState)\n",
    "\n",
    "# query -> retrieve_document -> eval document  response\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "# graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "# graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory\n",
    "    , interrupt_before=[\"tools\"]\n",
    ")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:57:40\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what time is it now\n",
      "--> chatbot messages : <class 'list'>\n",
      "--> chatbotmessages : [HumanMessage(content='where?', additional_kwargs={}, response_metadata={}, id='602a1a28-19e5-4280-9364-8be63d222429'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T04:47:38.948681777Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5116103347, 'load_duration': 4525813865, 'prompt_eval_count': 188, 'prompt_eval_duration': 330000000, 'eval_count': 21, 'eval_duration': 259000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': [{'function': {'name': 'tavily_search_results_json', 'arguments': {'query': 'where'}}}]}}, id='run-c293fa14-c783-4a7e-b6fa-5b8449e89cf1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'where'}, 'id': 'cf9a2c38-81a8-4a0a-8eeb-53f490e34651', 'type': 'tool_call'}], usage_metadata={'input_tokens': 188, 'output_tokens': 21, 'total_tokens': 209}), ToolMessage(content='[{\"url\": \"https://www.dictionary.com/e/where-vs-were/\", \"content\": \"\\\\u26a1 Quick summary. The word where (pronounced [ wair ]) is commonly used to ask about place or location (Where are you?) or indicate those things (I told him where I was).The word were (pronounced [ wur ]) is a past tense form of the irregular verb be that is used with plural subjects (The cupcakes were delicious) and the pronouns you and they regardless of whether they are singular or plural\"}, {\"url\": \"https://www.si.com/college/tennessee/football/college-football-playoff-rankings-and-seeding-revealed-where-is-tennessee-ranked-01jekfahq7rr\", \"content\": \"The final college football playoff rankings have been revealed. Where are the Tennessee Volunteers ranked? Conference championship weekend wrapped up on Saturday night as Clemson, Oregon, Georgia\"}, {\"url\": \"https://www.merriam-webster.com/dictionary/where\", \"content\": \"Word History\\\\nAdverb\\\\nMiddle English, from Old English hw\\\\u00c7\\\\u00a3r; akin to Old High German hw\\\\u00c4\\\\ufffdr where, Old English hw\\\\u00c4\\\\ufffd who\\\\n\\\\u00e2\\\\u20ac\\\\u201d more at who\\\\nAdverb\\\\nbefore the 12th century, in the meaning defined at sense 1a\\\\nConjunction\\\\n12th century, in the meaning defined at sense 1a\\\\nNoun\\\\n15th century, in the meaning defined at sense 1\\\\nPhrases Containing where\\\\nDictionary Entries Near where\\\\nwhen you come (right) down to it\\\\nwhere\\\\nwhereabouts\\\\nCite this Entry\\\\n\\\\u201cWhere.\\\\u201d where\\\\nadverb\\\\nwhere\\\\nconjunction\\\\nwhere\\\\nnoun\\\\nSynonyms\\\\nAdverb\\\\nNoun\\\\nExamples of where in a Sentence\\\\nThese examples are programmatically compiled from various online sources to illustrate current usage of the word \\'where.\\' Share\\\\nKids Definition\\\\nwhere\\\\nwhere\\\\nwhere\\\\nMore from Merriam-Webster on where\\\\nNglish: Translation of where for Spanish Speakers\\\\nBritannica English: Translation of where for Arabic Speakers\\\\nSubscribe to America\\'s largest dictionary and get thousands more definitions and advanced search\\\\u2014ad free!\\\\n Absent Letters That Are Heard Anyway\\\\nPopular in Wordplay\\\\nThe Words of the Week - Mar. 22\\\\n12 Words for Signs of Spring\\\\n9 Superb Owl Words\\\\n\\'Gaslighting,\\' \\'Woke,\\' \\'Democracy,\\' and Other Top Lookups\\\\nFan Favorites: Your Most Liked Words of the Day 2023\\\\nGames & Quizzes\\\\nLearn a new word every day. Popular in Grammar & Usage\\\\n8 Grammar Terms You Used to Know, But Forgot\\\\nHomophones, Homographs, and Homonyms\\\\nCommonly Misspelled Words\\\\nHow to Use Em Dashes (\\\\u00e2\\\\u20ac\\\\u201d), En Dashes (\\\\u00e2\\\\u20ac\\\\u201c) , and Hyphens (-)\\\\n\"}]', name='tavily_search_results_json', id='f6c1603b-e4e3-464c-9ea4-d691e5df1d59', tool_call_id='cf9a2c38-81a8-4a0a-8eeb-53f490e34651'), AIMessage(content='The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\\n\\nSome common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\\n\\nThe word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-09T04:51:07.454343456Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2987319958, 'load_duration': 62368245, 'prompt_eval_count': 739, 'prompt_eval_duration': 427000000, 'eval_count': 140, 'eval_duration': 2008000000, 'message': {'role': 'assistant', 'content': 'The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\\n\\nSome common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\\n\\nThe word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".', 'images': None, 'tool_calls': None}}, id='run-cbf213a2-34d7-426b-9823-c8de06f60ae7-0', usage_metadata={'input_tokens': 739, 'output_tokens': 140, 'total_tokens': 879}), HumanMessage(content='what time is it now', additional_kwargs={}, response_metadata={}, id='10a5b390-7737-43dc-9a8b-d386b58183f5')]\n",
      "--> TAVILY_API_KEY_6 : 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\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (63bbb5f8-c994-472e-b97f-e4028997ee33)\n",
      " Call ID: 63bbb5f8-c994-472e-b97f-e4028997ee33\n",
      "  Args:\n",
      "    query: current time\n",
      "Goodbye!\n",
      "⏳ 실행 시간: 15.43초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test1\"}}\n",
    "\n",
    "# stream_graph_updates 함수는 사용자의 입력을 받아 그래프를 통해 응답을 스트리밍하는 함수입니다\n",
    "def stream_graph_updates(user_input: str):\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# 메인 대화 루프입니다\n",
    "while True:\n",
    "        # 사용자로부터 입력을 받습니다\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # 종료 명령어를 확인합니다 (quit, exit, q)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 사용자 입력을 처리하여 응답을 생성합니다\n",
    "        stream_graph_updates(user_input)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stream_graph_updates 함수는 사용자의 입력을 받아 그래프를 통해 응답을 스트리밍하는 함수입니다\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # graph.stream()을 사용하여 사용자 입력을 그래프에 전달하고 응답을 스트리밍합니다\n",
    "    # {\"messages\": [(\"user\", user_input)]} 형태로 입력을 포맷팅합니다\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        # 각 이벤트에서 값을 추출하여 출력합니다\n",
    "        for value in event.values():\n",
    "            # Assistant: 프리픽스와 함께 메시지의 마지막 컨텐츠를 출력합니다\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 사용자 입력을 처리하여 응답을 생성합니다\n",
    "stream_graph_updates(\"너는 누구야?\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:53:08\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The word \"where\" is an adverb that can be used in various ways, such as asking about a place or location (Where are you?), indicating those things (I told him where I was), and as a conjunction. It can also be used as a noun to refer to a person or place.\n",
      "\n",
      "Some common synonyms for the word \"where\" include \"whence\", \"whereabouts\", and \"hither\".\n",
      "\n",
      "The word \"where\" has a rich history, dating back to Middle English, and its meaning has evolved over time. In modern usage, it is commonly used in phrases such as \"right down to it\" or \"when you come (right) down to it\".\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next\n",
    "\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(existing_message.tool_calls)\n",
    "\n",
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 13:59:44\n",
      "{'configurable': {'thread_id': 'test1'}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (63bbb5f8-c994-472e-b97f-e4028997ee33)\n",
      " Call ID: 63bbb5f8-c994-472e-b97f-e4028997ee33\n",
      "  Args:\n",
      "    query: current time\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='8961f990-3d44-43de-a006-3c65df908a63', tool_call_id='63bbb5f8-c994-472e-b97f-e4028997ee33'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='49f8aec7-209a-446a-a45f-06e57340600c')]\n",
      "⏳ 실행 시간: 0.00초\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-11-28 15:05:20\n",
      "--> messages : <class 'list'>\n",
      "--> messages : [HumanMessage(content='현재 시간은?', additional_kwargs={}, response_metadata={}, id='da3b46ed-a651-45d4-a1e2-d64841f2bc5e')]\n",
      "--> chatbot : after llm.invoke : 현재 시간은 다음과 같습니다: [날짜, 시간 포맷팅 규칙에 따라 현재 날짜와 시간을 표시합니다]\n",
      "{'messages': [HumanMessage(content='현재 시간은?', additional_kwargs={}, response_metadata={}, id='da3b46ed-a651-45d4-a1e2-d64841f2bc5e'), AIMessage(content='현재 시간은 다음과 같습니다: [날짜, 시간 포맷팅 규칙에 따라 현재 날짜와 시간을 표시합니다]', additional_kwargs={}, response_metadata={}, id='f7ff2f24-6e70-4b00-abeb-e76ee07443f0')]}\n",
      "⏳ 실행 시간: 15.82초\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=10)\n",
    "\n",
    "inputs = State(messages=\"현재 시간은?\")\n",
    "outputs = graph.invoke(inputs, config)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕒 현재 시간: 2024-12-09 15:14:30\n",
      "\u001b[33m📥 Attempting to download repository as a ZIP archive...\u001b[0m\n",
      "\u001b[33mURL: https://github.com/langchain-ai/react-agent/archive/refs/heads/main.zip\u001b[0m\n",
      "\u001b[32m✅ Downloaded and extracted repository to /home/stlim/projects/samples/customAIService/langchain/langgraph-server\u001b[0m\n",
      "\u001b[32m\u001b[1m🎉 New project created at /home/stlim/projects/samples/customAIService/langchain/langgraph-server\u001b[0m\n",
      "cp: cannot stat '.env': No such file or directory\n",
      "Obtaining file:///home/stlim/projects/samples/customAIService/langchain/langgraph-server\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: langgraph>=0.2.6 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.2.56)\n",
      "Requirement already satisfied: langchain-openai>=0.1.22 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.2.11)\n",
      "Requirement already satisfied: langchain-anthropic>=0.1.23 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.3.0)\n",
      "Requirement already satisfied: langchain>=0.2.14 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.3.10)\n",
      "Requirement already satisfied: langchain-fireworks>=0.1.7 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.2.5)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: langchain-community>=0.2.17 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.3.10)\n",
      "Requirement already satisfied: tavily-python>=0.4.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from react-agent==0.0.1) (0.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (3.11.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain>=0.2.14->react-agent==0.0.1) (8.5.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.39.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-anthropic>=0.1.23->react-agent==0.0.1) (0.40.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-anthropic>=0.1.23->react-agent==0.0.1) (0.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-community>=0.2.17->react-agent==0.0.1) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-community>=0.2.17->react-agent==0.0.1) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-community>=0.2.17->react-agent==0.0.1) (2.6.1)\n",
      "Requirement already satisfied: fireworks-ai>=0.13.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-fireworks>=0.1.7->react-agent==0.0.1) (0.15.10)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-fireworks>=0.1.7->react-agent==0.0.1) (1.57.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-openai>=0.1.22->react-agent==0.0.1) (0.8.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langgraph>=0.2.6->react-agent==0.0.1) (2.0.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langgraph>=0.2.6->react-agent==0.0.1) (0.1.43)\n",
      "Requirement already satisfied: httpx in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from tavily-python>=0.4.0->react-agent==0.0.1) (0.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.14->react-agent==0.0.1) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from anthropic<1,>=0.39.0->langchain-anthropic>=0.1.23->react-agent==0.0.1) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from anthropic<1,>=0.39.0->langchain-anthropic>=0.1.23->react-agent==0.0.1) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from anthropic<1,>=0.39.0->langchain-anthropic>=0.1.23->react-agent==0.0.1) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from anthropic<1,>=0.39.0->langchain-anthropic>=0.1.23->react-agent==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from anthropic<1,>=0.39.0->langchain-anthropic>=0.1.23->react-agent==0.0.1) (4.12.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.17->react-agent==0.0.1) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.17->react-agent==0.0.1) (0.9.0)\n",
      "Requirement already satisfied: httpx-ws in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from fireworks-ai>=0.13.0->langchain-fireworks>=0.1.7->react-agent==0.0.1) (0.7.0)\n",
      "Requirement already satisfied: Pillow in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from fireworks-ai>=0.13.0->langchain-fireworks>=0.1.7->react-agent==0.0.1) (11.0.0)\n",
      "Requirement already satisfied: certifi in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from httpx->tavily-python>=0.4.0->react-agent==0.0.1) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from httpx->tavily-python>=0.4.0->react-agent==0.0.1) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from httpx->tavily-python>=0.4.0->react-agent==0.0.1) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python>=0.4.0->react-agent==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain>=0.2.14->react-agent==0.0.1) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain>=0.2.14->react-agent==0.0.1) (24.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph>=0.2.6->react-agent==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.6->react-agent==0.0.1) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain>=0.2.14->react-agent==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks>=0.1.7->react-agent==0.0.1) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.14->react-agent==0.0.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.14->react-agent==0.0.1) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain>=0.2.14->react-agent==0.0.1) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain>=0.2.14->react-agent==0.0.1) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.2.14->react-agent==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.1.22->react-agent==0.0.1) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain>=0.2.14->react-agent==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.17->react-agent==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: wsproto in /home/stlim/projects/samples/customAIService/.venv/lib/python3.12/site-packages (from httpx-ws->fireworks-ai>=0.13.0->langchain-fireworks>=0.1.7->react-agent==0.0.1) (1.2.0)\n",
      "Building wheels for collected packages: react-agent\n",
      "  Building editable for react-agent (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for react-agent: filename=react_agent-0.0.1-0.editable-py3-none-any.whl size=6958 sha256=bc09607120e9b004ea3e64065b3e9340382725532d550255cd968d1f98d5d45b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m4rdq7to/wheels/e1/68/36/541b1d57fbf6b08e2b8af7f9cb052d7426e48a9f16662b3dd0\n",
      "Successfully built react-agent\n",
      "Installing collected packages: react-agent\n",
      "  Attempting uninstall: react-agent\n",
      "    Found existing installation: react-agent 0.0.1\n",
      "    Uninstalling react-agent-0.0.1:\n",
      "      Successfully uninstalled react-agent-0.0.1\n",
      "Successfully installed react-agent-0.0.1\n",
      "INFO:langgraph_api.cli:\n",
      "\n",
      "        Welcome to\n",
      "\n",
      "╦  ┌─┐┌┐┌┌─┐╔═╗┬─┐┌─┐┌─┐┬ ┬\n",
      "║  ├─┤││││ ┬║ ╦├┬┘├─┤├─┘├─┤\n",
      "╩═╝┴ ┴┘└┘└─┘╚═╝┴└─┴ ┴┴  ┴ ┴\n",
      "\n",
      "- 🚀 API: \u001b[36mhttp://127.0.0.1:2024\u001b[0m\n",
      "- 🎨 Studio UI: \u001b[36mhttps://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\u001b[0m\n",
      "- 📚 API Docs: \u001b[36mhttp://127.0.0.1:2024/docs\u001b[0m\n",
      "\n",
      "This in-memory server is designed for development and testing.\n",
      "For production use, please use LangGraph Cloud.\n",
      "\n",
      "\n",
      "\u001b[2m2024-12-09T06:14:36.456855Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWill watch for changes in these directories: ['/home/stlim/projects/samples/customAIService/langchain/langgraph-server']\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:36.457175Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUvicorn running on http://127.0.0.1:2024 (Press CTRL+C to quit)\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mcolor_message\u001b[0m=\u001b[35mUvicorn running on \u001b[1m%s://%s:%d\u001b[0m (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:36.457644Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarted reloader process [134741] using WatchFiles\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mcolor_message\u001b[0m=\u001b[35mStarted reloader process [\u001b[36m\u001b[1m134741\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:36.991801Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarted server process [134782]\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mcolor_message\u001b[0m=\u001b[35mStarted server process [\u001b[36m%d\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:36.991933Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWaiting for application startup.\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.067206Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m2 changes detected            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mwatchfiles.main\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.259797Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRegistering graph with id 'agent'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.graph\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mgraph_id\u001b[0m=\u001b[35magent\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.260232Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting metadata loop        \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.metadata\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.264330Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mApplication startup complete. \u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.264694Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting 1 background workers \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.266025Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWorker stats                  \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mactive\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mavailable\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmax\u001b[0m=\u001b[35m1\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.266411Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGET /ok 200 0ms               \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.server\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mlatency_ms\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mmethod\u001b[0m=\u001b[35mGET\u001b[0m \u001b[36mpath\u001b[0m=\u001b[35m/ok\u001b[0m \u001b[36mpath_params\u001b[0m=\u001b[35m{}\u001b[0m \u001b[36mproto\u001b[0m=\u001b[35m1.1\u001b[0m \u001b[36mquery_string\u001b[0m=\u001b[35m\u001b[0m \u001b[36mreq_header\u001b[0m=\u001b[35m{'accept-encoding': 'identity', 'host': '127.0.0.1:2024', 'user-agent': 'Python-urllib/3.12', 'connection': 'close'}\u001b[0m \u001b[36mres_header\u001b[0m=\u001b[35m{'content-length': '11', 'content-type': 'application/json'}\u001b[0m \u001b[36mroute\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35m200\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.266832Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mQueue stats                   \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mmax_age_secs\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mmed_age_secs\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mn_pending\u001b[0m=\u001b[35m0\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.418135Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m9 changes detected            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mwatchfiles.main\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "🎨 Opening Studio in your browser...\n",
      "\u001b[2m2024-12-09T06:14:37.477833Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m🎨 Opening Studio in your browser...\u001b[0m [\u001b[0m\u001b[1m\u001b[34mbrowser_opener\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mmessage\u001b[0m=\u001b[35m🎨 Opening Studio in your browser...\u001b[0m\n",
      "URL: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024&organizationId=bed8bbc8-94f8-413b-bfe5-57fb240722ff\n",
      "\u001b[2m2024-12-09T06:14:37.478096Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mURL: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024&organizationId=bed8bbc8-94f8-413b-bfe5-57fb240722ff\u001b[0m [\u001b[0m\u001b[1m\u001b[34mbrowser_opener\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mmessage\u001b[0m=\u001b[35mURL: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024&organizationId=bed8bbc8-94f8-413b-bfe5-57fb240722ff\u001b[0m\n",
      "\u001b[2m2024-12-09T06:14:37.664823Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: POST https://api.smith.langchain.com/v1/metadata/submit \"HTTP/1.1 204 No Content\"\u001b[0m [\u001b[0m\u001b[1m\u001b[34mhttpx\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "/usr/bin/xdg-open: 882: x-www-browser: not found\n",
      "/usr/bin/xdg-open: 882: firefox: not found\n",
      "/usr/bin/xdg-open: 882: iceweasel: not found\n",
      "/usr/bin/xdg-open: 882: seamonkey: not found\n",
      "/usr/bin/xdg-open: 882: mozilla: not found\n",
      "/usr/bin/xdg-open: 882: epiphany: not found\n",
      "/usr/bin/xdg-open: 882: konqueror: not found\n",
      "/usr/bin/xdg-open: 882: chromium: not found\n",
      "/usr/bin/xdg-open: 882: chromium-browser: not found\n",
      "/usr/bin/xdg-open: 882: google-chrome: not found\n",
      "/usr/bin/xdg-open: 882: www-browser: not found\n",
      "/usr/bin/xdg-open: 882: links2: not found\n",
      "/usr/bin/xdg-open: 882: elinks: not found\n",
      "/usr/bin/xdg-open: 882: links: not found\n",
      "/usr/bin/xdg-open: 882: lynx: not found\n",
      "/usr/bin/xdg-open: 882: w3m: not found\n",
      "xdg-open: no method available for opening 'https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024&organizationId=bed8bbc8-94f8-413b-bfe5-57fb240722ff'\n",
      "\u001b[2m2024-12-09T06:15:37.737352Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWorker stats                  \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mactive\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mavailable\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmax\u001b[0m=\u001b[35m1\u001b[0m\n",
      "\u001b[2m2024-12-09T06:15:37.739234Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mQueue stats                   \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mmax_age_secs\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mmed_age_secs\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mn_pending\u001b[0m=\u001b[35m0\u001b[0m\n",
      "^C\n",
      "\u001b[2m2024-12-09T06:16:02.172111Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mShutting down                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.273862Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWaiting for application shutdown.\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.274254Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mShutting down background workers\u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.queue\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.274601Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCancelling remote graphs      \u001b[0m [\u001b[0m\u001b[1m\u001b[34mlanggraph_api.graph\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.275827Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mApplication shutdown complete.\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.276141Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFinished server process [134782]\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mcolor_message\u001b[0m=\u001b[35mFinished server process [\u001b[36m%d\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-12-09T06:16:02.282702Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStopping reloader process [134741]\u001b[0m [\u001b[0m\u001b[1m\u001b[34muvicorn.error\u001b[0m]\u001b[0m \u001b[36mapi_variant\u001b[0m=\u001b[35mlocal_dev\u001b[0m \u001b[36mcolor_message\u001b[0m=\u001b[35mStopping reloader process [\u001b[36m\u001b[1m134741\u001b[0m]\u001b[0m\n",
      "⏳ 실행 시간: 92.15초\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"langgraph-cli[inmem]\" python-dotenv\n",
    "!rm -rf langgraph-server\n",
    "!langgraph new langgraph-server --template react-agent-python\n",
    "!cp ../.env langgraph-server/.env\n",
    "!cd langgraph-server && pip install -q -e . && langgraph dev\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
